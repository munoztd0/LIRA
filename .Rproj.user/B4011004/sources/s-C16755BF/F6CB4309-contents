---
title: "OBIWAN LEAN VS. OBESE ANALYSIS REPORT"
author: "David Munoz Tord"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:  
    includes:
      in_header: header.html
    css: "style.css"
    code_folding: "hide"
    toc: true
    toc_float: false
    number_sections: false
  pdf_document:
    extra_dependencies: ["float"]
repro:
  data:
    HED: data/HEDONIC.csv
    INST: data/INST.csv
    PAV: data/PAV.csv
    PIT: data/PIT.csv
    info: data/info.csv
    intern: data/internal.csv
    medic: data/medic.csv
    pupil: data/pupil.csv
    
  packages: [ aaronpeikert/repro@devel, crsh/papaja@devel, stan-dev/cmdstanr@HEAD, samhforbes/PupillometryR@HEAD, knitr, afex, emmeans, parallel, tidyverse, car, lspline, JWileymisc, kableExtra, ggthemes, MBESS, sjPlot, Rmisc, janitor, rlist, sessioninfo, stringr, XML, bayestestR, optimx, sjstats, brms, pbkrtest, caret, pander, hBayesDM, report, zoo, ggpubr, tidybayes, logspline]
  scripts: 
    - R/clean.R
  apt:
    - libgsl0-dev
    - jags
---


### Setup {-}
<!-- # TO DO -->
  
<!--   # For Linux: download libv8 during installation -->
<!-- Sys.setenv(DOWNLOAD_STATIC_LIBV8=1) -->
<!-- install.packages("V8") -->
```{r setup, results='hide', message=FALSE, warning=FALSE}

library(repro)

# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()

# load data
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
medic <- automate_load_data(medic, read.csv, stringsAsFactors = T)
pupil <- automate_load_data(pupil, read.csv, stringsAsFactors = T)

## we recommend running this is a fresh R session or restarting your current session
#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#install_cmdstan()


# check_git(); check_make(); check_docker() #check if installed

sessio = session_info(); #opts_chunk$set(echo = F, message=F, warning=F) # set echo F for all
```

This file was automatically created via `the Repro package (version 0.1.0)` using  `r sessio$platform[1]`

<!-- May I suggest running `repro::automate()`? This will create a `Dockerfile` & `Makefile` based on every RMarkdown in this folder and the special yamls in them. date: "`r format(Sys.time(), '%d %B, %Y')`" -->
<!-- add ENV DEBIAN_FRONTEND=noninteractive -->

  

```{r options, results='hide', message=FALSE, warning=FALSE}
niter = 5000; warm = 1000; chains = 4; cores = 4 # number of iterations (to change if you want to quick check and warmups (BUT chains and BF might be really unstable if you have less than 20'000 iter (4x5000) ) #or also parallel::detectCores()/2)
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = cores) #remove scientific notation # remove warnings #set contrasts to sum !
 #parallel::detectCores()/2
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
#emm_options(pbkrtest.limit = 8000) #increase repetitions limit for frequentist stats

source('R/plots.R', echo=F)# plot specification
source('R/utils.R', echo=F)# useful functions

panderOptions('knitr.auto.asis', FALSE) #remove auto styling

# Look at R/clean.R (listed in the YAML) which does all the preprocessing for more info

# If you are unsure weather or not you have `git` `make` & `docker`.
# check_git()
# check_make()
# check_docker()
```

```{r clean, include=F}
# this chunk runs R/clean.R (listed in the YAML) which does all the preprocessing
```
### Description
TODO blabla\

### Demographics
```{r demographics}
egltable(c("age", "gender"), 
         g = "group", data = df, strict = T) %>%
  kbl(caption ="Summary statistics by group", digits = 2) %>%
  kable_styling(latex_options = "HOLD_position", position = "left", full_width = F) %>%
  row_spec(0,bold=T,align='c')

BMI = ddply(df,~group,summarise,mean=mean(BMI),sd=sd(BMI), min = min(BMI), max = max(BMI), n = length(unique(id))); 
BMI %>%
  kbl(caption ="BMI by group", digits = 2) %>%
  kable_styling(latex_options = "HOLD_position", position = "left", full_width = F) %>%
  row_spec(0,bold=T,align='c')

```


<!-- ### Biomedical data -->
<!-- #### Variable Selection {-} -->
```{r var_plot, warning=FALSE, cache=F, fig.align="center", out.width="90%"}
#fig.cap="Box-plot of all biomedical predictors per intervention."

# Boxplot of biomedical variables per group
# ggplot(med)+
#   geom_boxplot(aes(group, n))+
#   facet_wrap(~feature, scales = "free")+
#   labs(title = "")+
#   theme_fivethirtyeight()+
#   theme(axis.title = element_text()) + 
#   ylab("Biomedical predictor's value (scaled)") + 
#   xlab('')

# Plot correlogram of numeric variables
#pairs(~., data = df[,8:19], main = "Scatterplot Matrix of variables")
#corrplot(cor(df[,8:19], use="pairwise.complete.obs"), type="lower")

```

```{r var_sel, include=T, cached=F,fig.align="center"}
#Recursive Feature Eliminations (CARET)
# 
# set.seed(666)
# 
# sizes = 1:length(dfmed)
# len = length(sizes)
# seeds <- vector(mode = "list", length = len)
# for(i in 1:(len-1)) seeds[[i]]<- sample.int(n=10000, size = length(sizes)+1)
# # for the last model
# seeds[[len]]<-sample.int(10000, 1)
# 
# RFEcontrol <- rfeControl(functions=rfFuncs, method="cv", number=10, seeds= seeds) # control options
# 
# rfeResults = rfe(x = dfmed[c(-1)], y = dfmed$group, sizes=sizes, rfeControl=RFEcontrol)
# predictors(rfeResults)
# plot(rfeResults, type=c("g", "o")) # look for the "elbow"

```
\

### Pavlvovian Conditioning Task 

#### Latency {-}
Latency = time to detect the target (ms) & condition = CS+ or CS-
```{r PAV_RT, include=FALSE, cache=F}

# Model
mf = formula(RT ~ condition*group*hungry + (condition|id) + (1|trialxcondition))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
# STAN is a probabilistic programming language that allows you to get full Bayesian statistical inference with MCMC sampling.
bmod_full = brm(mf, data=PAV.clean, family = exgaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF  3) account for the skewness of reaction times #family = "exgaussian"


#lmer to compare
fmod_full = lmer(mf , data = PAV.clean, REML=F, control = control )
```

```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*y"), type ="areas")

trace = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*y"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "group", binwidth = 1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit -> accounting for skewness, nice!

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagRT <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagRT, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```

```{r PAV_tab, include=FALSE, cache=F}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_beta", "prior_sigma"))



# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------


# fmod_inter = update(fmod_full,  ~ .-condition:group) #evaluate interaction
# fmod_cond = update(fmod_full,  ~ .-condition) #evaluate condition
# fmod_group =  update(fmod_full, ~ .-group) #evaluate group
# 
# # p-value from bootstrap distribution
# LRT_inter = PBmodcomp(fmod_full, fmod_inter, nsim = 500, seed = 123, cl=cores) 
# LRT_cond = PBmodcomp(fmod_full, fmod_cond, nsim = 500, seed = 123, cl=cores) 
# LRT_group = PBmodcomp(fmod_inter, fmod_group, nsim = 500, seed = 123, cl=cores)
# 
# ems = emmeans(fmod_full, pairwise ~condition:group)
# #con = contrast(ems$emmeans, method = list(PAV_obe - PAV_lean)) #diff of diff
# con_ob = contrast(ems$emmeans, method = list(PAV_obe)) #PAV ob
# con_lean = contrast(ems$emmeans, method = list(PAV_lean)) #PAV lean
# con = rbind(con_ob, con_lean)

# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Latency (ms)", file = "tmp/temp1.html", transform = NULL,  rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r PAV_res}

print(paste("Bayesian general linear mixed model (exGaussian family with a identity link) (estimated using MCMC sampling with " ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict Latency (ms) with condition, group and hungry (formula: RT ~ condition * group * hungry). The model included condition, id and trialxcondition as random effects (formula: list(~condition | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00) and student_t (location = 0.00, scale = 133.90) distributions for beta and sd respectively"))

full_tab

report[4]

tables <- list.clean(readHTMLTable("tmp/temp1.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble(); #table = tables2[1:length(BF_10),1:4];  table$BF10 = BF_10


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2]); colnames(tmp) =  tmp[1,]
pander:: pander(tmp[2,])


```
\

#### Plot Latency {-}
```{r PAV_RT_plot, message=FALSE, warning=FALSE, cache=F, fig.align="center", fig.cap="A) Posterior distribution by Pavlovian cue. B) Highest density interval (90% HDI) of the posterior distribution difference for the latency to respond between CS+ and CS-"}

dfdraws = bmod_full %>%
    spread_draws(`b_condition` )


HDI_RT = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw() + html_theme  


dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>%
    ggplot(aes(x = as_factor(condition) , y = .value,  fill = as_factor(condition))) +
    #geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    labs(x = "",y = "Latency (ms)", title = "") + 
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_x_discrete(labels=c("CS-", "CS+")) +
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(400,550, by = 50)), limits = c(380,575)) +
    theme_bw()

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figureRT <- ggarrange(plt_bayes_html, HDI_RT,
                    labels = c("A", "B"),
                    ncol = 2)
figureRT

# RT

dfR <- summarySEwithin(PAV.means,
                       measurevar = "RT",
                       withinvars = "condition", 
                       idvar = "id")

dfR$cond <- ifelse(dfR$condition == "1", -0.25, 0.25)
PAV.means$cond <- ifelse(PAV.means$condition == "1", -0.25, 0.25)
set.seed(666)
PAV.means <- PAV.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
                                  grouping = interaction(id, cond))

pp <- ggplot(PAV.means, aes(x = cond, y = RT, 
                            fill = as.factor(condition), color = as.factor(condition))) +
  geom_line(aes(x = condjit, group = id), alpha = .3, size = 0.5, color = 'gray') +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
  geom_point(aes(x = condjit, shape = as.factor(group)), alpha = .3) +
  geom_crossbar(data = dfR, aes(y = RT, ymin=RT-ci, ymax=RT+ci), width = 0.2 , alpha = 0.1)+
  ylab('Latency (ms)')+
  xlab('Conditioned stimulus')+
  #scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(200,800, by = 200)), limits = c(180,875)) +
  scale_x_continuous(labels=c("CS+", "CS-"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_shape_manual(name="Group", labels=c("Lean", "Obese"), values = c(1, 2)) +
  theme_bw()

plt = pp + averaged_theme 
#pp + html_theme 
```
```{r PAV_RT_saveFIG, include=FALSE}
cairo_pdf('figures/Figure_PavlovianRT.pdf')
print(plt)
dev.off()


cairo_pdf('figures/Figure_Pavlovian_HDI_RT.pdf')
print(figureRT)
dev.off()

```


```{r PAV_pup, include=FALSE, cache=F}
# Estimating divergences with functional data analysis (FDA)

#CS+ minus CS- Late 

#We can now convert this to a functional data structure, made up of curves. To do this for this data we are going to make it up of cubics (order = 4) with 10 knots (basis = 10). See Ramsay, Hooker & Spencer (2010) and the fda package.
spline_data <- create_functional_data(data = differencesLate,
                                      pupil = pupil, basis =10, order = 4)

plot(differencesLate, pupil = pupil, geom = 'line')
plot(spline_data, pupil = pupil, geom = 'line', colour = 'blue') #That looks like it's done a pretty good job capturing the data.

#The advantage of this kind of analysis is that we can treat each curve as a function, and run a single functional t-test to work out during which window there are divergences.

ft_data <- run_functional_t_test(data = spline_data,
                                 pupil = pupil,
                                 alpha = 0.05)

plt = plot(ft_data, show_divergence = T, colour = 'red', fill = 'orange')
diverg_plot = plt + scale_x_continuous(name="Time (ms)", limits=c(0, 8000), breaks=c(seq.int(0, 8000, by = 500))) + html_theme  

#no divergences CS+>CS- neither in late or early < late..
```

#### Plot Pupillometry {-}
```{r PAV_pup_plot, warning=FALSE, cache=F, message = FALSE, results='hide', fig.align="center", fig.cap="Pupil change by pavlvovian cue (late acquisition)."}
bst = summarySE(late, measurevar="pupil", groupvars=c("condition", "Timebin"), na.rm = TRUE)
bst$Timebin = bst$Timebin * 100
bst$condition = revalue(bst$condition, c("32"="CS+", "16"="CS-")) #, "64" ="Baseline"


SE_plot <- ggplot(bst)+
  aes(Timebin/1000, pupil,  color=condition) +
  stat_summary(fun = "mean", geom = "line", size = 1) +
  theme_bw() +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq.int(0,8, by = 1)), limits = c(-0.1,8.15)) + 
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(-0.010,0.010, by = 0.005)), limits = c(-0.010,0.010)) + 
  labs(x = "Time (s)",y = "Change in Pupil size (au)", title = "") + #(change from baseline (a.u.)
  #geom_hline(yintercept=0.0) +
  geom_ribbon(aes(ymin = pupil - se, ymax = pupil + se), alpha = 0.1) +
  #geom_rect(aes(xmin=0, xmax=4, ymin=-0.01, ymax=-0.009), fill="grey90", color="grey90", alpha=0.01) +
  geom_vline(xintercept = 3, lty=2) +
  geom_vline(xintercept = 4, lty=1) +
  annotate(geom="text", x=5, y=-0.009, label="\u2190 Delivery") +
  scale_color_manual(values=c("CS+"= pal[2], "CS-"=  pal[1]), name = 'Condition')+
  scale_fill_manual(values=c("CS+"= pal[2], "CS-"=  pal[1]), name = 'Condition') 
  # + scale_linetype_manual(values=c("CS+"= 1, "CS-"= 2), guide = 'none')

ppp <- SE_plot + theme_bw() + theme(strip.background = element_rect(fill="white"))
ppp

# 
# #22
# bst = summarySEwithin(pupil_data, measurevar="pupil", withinvars = c("condition", "Timebin", "phase"), idvar = "ID", na.rm = TRUE)
# 
# 
# bst$condition = revalue(bst$condition, c("32"="CS+", "16"="CS-"))
# bst$Timebin = (as.numeric(as.character(bst$Timebin)) * 100) /1000 #convert to sec
# labels <- c("early" = "Early", "late" = "Late")
# 
# SE2_plot <- ggplot(bst)+
#   aes(Timebin, pupil, linetype=phase, color=condition, fill = condition) + 
#   stat_summary(fun = "mean", geom = "line", size = 1) + 
#   theme_bw() +
#   labs(x = "Time (s)",y = "Change in Pupil size (au)") + #(change from baseline (a.u.)
#   geom_hline(yintercept=0.0) + 
#   geom_ribbon(aes(ymin = pupil - se, ymax = pupil + se), alpha = 0.1) + 
#   #facet_wrap(~phase, labeller=labeller(phase = labels)) + 
#   scale_color_manual(values=c("CS+"= pal[2], "CS-"=  pal[1]), name = 'Condition')+
#   scale_fill_manual(values=c("CS+"= pal[2], "CS-"=  pal[1]), name = 'Condition')+
#   #scale_linetype_manual(values=c("CS+"= 1, "CS-"= 2), guide = 'none')+ 
#   scale_x_continuous(expand = c(0, 0), breaks = c(seq.int(0,8, by = 1)), limits = c(0.1,8)) +    geom_vline(xintercept = 3, lty=2) + 
#    geom_vline(xintercept = 4, lty=2)
#  # + geom_vline(xintercept = 0.3, lty=2) +   geom_vline(xintercept = 0.4, lty=2) + geom_vline(xintercept = 0.9, lty=2) +   geom_vline(xintercept = 1.25, lty=2)
# 
# 
# ppp <- SE2_plot + theme_bw() + theme(strip.background = element_rect(fill="white"), axis.text.x = element_text(angle = 90))
# ppp

```
```{r, warning=FALSE, cache=F, fig.align="center", fig.cap="Estimating divergences with functional data analysis (FDA). No functional divergences between CS+>CS- neither in late acquisition or early < late acquisition (critical value for n = 57 is 2.00)."}
diverg_plot +  theme(axis.text.x = element_text(angle = 90))
```
```{r PAV_pup_saveFIG, include=FALSE}
cairo_pdf('figures/Figure_PavlovianPup.pdf')
print(ppp)
dev.off()
```
\

#### Perceived liking (Pavlovian Cue)

Ratings = how pleasant is the clue (0-100, no repetitions)   &   condition = CS+ or CS-
```{r PAV_Lik, include=FALSE, message=FALSE, cache=F}
# Model
mf = formula(liking ~ condition*group*hungry + (condition|id))


# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
bmod_full = brm(mf, data=PAV.means, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4))  # a lot to unwind here..  1) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 2) we need to sample priors and save parameters for computing BF  


#lm to compare
fmod_full <- lmer(update(mf, ~ .-(condition|id)+(1|id)) , data= PAV.means) #cannot maximize random structure
```
```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*u"), type ="areas")

trace = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*u"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "group", binwidth = 1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagLik <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagLik, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```


```{r PAV_tab_lik, include=FALSE, cache=F}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_beta", "prior_sigma"))



# -------------------------------------- FREQUENTIST STATS: -----------------------------------------------

# model = aov_car(liking ~ cond + grp + hungry + Error(id/cond), data= PAV.means, factorize = F, anova_table = list(correction = "GG", es = "pes"), type ="II")
# res = nice(model, MSE=F); ref_grid(model) #triple check everything is centered at 0
# 
# #calculate Partial eta-squared and its 90 % CI for each effect
# pes_CI = pes_ci(liking ~ cond*grp + age + gender + thirsty + hungry + Error(id/cond), PAV.means, type ="II");

# -------------------------------------- Regression table summary --------------------------------------

tab_model(fmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Perceived liking", file = "tmp/temp2.html", rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r PAV_res_lik}

print(paste("Bayesian linear mixed model (estimated using MCMC sampling with" ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict liking with condition, group and hungry (formula: liking ~ condition * group * hungry). The model included condition and id as random effects (formula: ~condition | id). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 18.80) distributions"))

full_tab

report[8]
tables <- list.clean(readHTMLTable("tmp/temp2.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+4),1:2]);
tmp[,4][1] = "R2"; tmp[,4][2] = gsub(".*/","",tmp[,2][2])
pander::pander(tmp[,1:2])


```

#### Plot Perceived liking (Pavlovian Cue) {-}
```{r PAV_lik_plot, message=FALSE, warning=FALSE, cache=F, fig.align="center", fig.cap="A) Posterior distribution by Pavlovian cue. B) Highest density interval (90% HDI) of the posterior distribution difference for the latency to respond between CS+ and CS-"}

dfdraws = bmod_full %>%
    spread_draws(`b_condition`,`b_hungry`, `b_condition:hungry` )


HDI_cond_PAV = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw()

HDI_hunger_PAV = plotHDI( dfdraws$`b_hungry` , credMass = .90, binSize = 100, Title = "") + theme_bw()

HDI_inter_PAV = plotHDI( dfdraws$`b_condition:hungry` , credMass = .90, binSize = 100, Title = "") + theme_bw()


dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>%
    ggplot(aes(x = as_factor(condition) , y = .value,  fill = as_factor(condition))) +
    geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    #geom_point(position = "jitter") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    ylab('Perceived liking')+
    xlab('')+
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_x_discrete(labels=c("CS-", "CS+")) +
     scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 25)), limits = c(-0.05,100.5)) +
    theme_bw()# + facet_wrap(~group, labeller=labeller(group =labels))

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 



# liking

dfR <- summarySEwithin(PAV.means,
                       measurevar = "liking",
                       withinvars = "condition", 
                       idvar = "id")

dfR$cond <- ifelse(dfR$condition == "1", -0.25, 0.25)
PAV.means$cond <- ifelse(PAV.means$condition == "1", -0.25, 0.25)
PAV.means <- PAV.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
                                  grouping = interaction(id, cond))

pp <- ggplot(PAV.means, aes(x = cond, y = liking, 
                            fill = as.factor(condition), color = as.factor(condition))) +
  geom_line(aes(x = condjit, group = id), alpha = .3, size = 0.5, color = 'gray') +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
  geom_point(aes(x = condjit, shape = as.factor(group)), alpha = .3) +
  geom_crossbar(data = dfR, aes(ymin=liking-ci, ymax=liking+ci), width = 0.2 , alpha = 0.1)+
  ylab('Perceived liking')+
  xlab('Conditioned stimulus')+
  scale_x_continuous(labels=c("CS+", "CS-"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
    scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 25)), limits = c(-0.05,100.5)) +
  scale_fill_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_shape_manual(name="Group", labels=c("Lean", "Obese"), values = c(1, 2)) +
  theme_bw()

plt = pp + averaged_theme 

figurePAVlik <- ggarrange(plt_bayes_html,HDI_cond_PAV,
                    labels = c("A", "B"),
                    ncol = 2)
figurePAVlik
```

```{r PAV_lik_saveFIG, include=FALSE}
cairo_pdf('figures/Figure_PavlovianLiking.pdf')
print(plt)
dev.off()


cairo_pdf('figures/Figure_Pavlovian_HDI_liking.pdf')
print(figurePAVlik)
dev.off()
```


### Instrumental Conditioning Task {-}
grips = number of times participant exceeded the force threshold to acquire the reward (Milkshake)
\

```{r INST, include=FALSE, cache=F}

# Model
mf1 = formula(grips ~ trial*group*hungry + (trial|id)) # LINEAR FIT  
mf2 = formula(grips ~  lspline(trial,5)*group*hungry + (trial|id)) # PIECEWISE REGRESSION WITH SPLINE AT 5

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
linmod = brm(mf1, data=INST, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4))  # a lot to unwind here..  1) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 2) we need to sample priors and save parameters for computing BF  

splinemod = update(linmod, formula. = mf2)

linmod$loo = loo(linmod); splinemod$loo = loo(splinemod)
comp = loo::loo_compare(linmod$loo, splinemod$loo) 

bmod_full = splinemod #winner model

#lmer to compare
fmod_full = lmer(mf2 , data = INST, REML=F, control = control )
```
\
Model Comparison between linear and piecewise with spline regression\
Best fit => Piecewise Regression with spline: smaller ELPD (expected log pointwise predictive density estimated via leave-one-out cross-validation) is better\
```{r}
comp = rownames_to_column(as_tibble(comp, rownames = NA)); colnames(comp)[1] = "model"
pander(comp[c(1:3,8:9)]) # so the splinemod was preferred as the other model had smaller ELPD. Thus, spline improved out-of-sample predictions. can also see: compare_ic(linmod, splinemod) but its deprecated
```


```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full,  pars =c("b_.*al"), type ="areas")

trace = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*y"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "group", binwidth = 0.01, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagINST <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagINST, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```

```{r INST_tab, include=FALSE, cache=F}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_beta", "prior_sigma"))

x = attributes(full_tab); x$clean_parameters[c(2:3,6:9,11:12),5] = c("trial<5",       "trial>5"  , "trial<5:group"  , "trial>5:group",  "trial<5:hungry", "trial>5:hungry", "trial<5:group:hungry" , "trial>5:group:hungry"); attributes(full_tab) = x


# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------

# fmod_spline =  update(fmod_full, ~ .-lspline(trial,5)) #evaluate trial spline
# 
# # p-value from bootstrap distribution
# LRT_spline = PBmodcomp(fmod_full, fmod_spline, nsim = 500, seed = 123, cl=cores)


# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Number of Grips", file = "tmp/temp3.html", transform = NULL,  rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r INST_res}

print(paste("Bayesian linear mixed model (estimated using MCMC sampling with" ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict grips with trial, group and hungry (formula: grips ~ lspline(trial, 5) + group + hungry + lspline(trial, 5):group + lspline(trial, 5):hungry + group:hungry + lspline(trial, 5):group:hungry). The model included id as random effect (formula: ~trial | id). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 7.40) distributions"))

full_tab

report[4]

tables <- list.clean(readHTMLTable("tmp/temp3.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t( tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,4:5] = tmp[,3:4]; tmp[,3] = c("N trial","24")
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)


```



#### Plot {-}
```{r INST_plot, echo = F, results='hide', warning=FALSE, message=FALSE, cache=F, fig.cap="Number of grips over trials."}

plt = conditional_effects(bmod_full,effects = "trial") #easier to extract spline with brms
dfTRIAL = as_tibble(plt$trial); dfTRIAL$grips = dfTRIAL$estimate__

#by groups
dfTRIALg <- summarySEwithin(INST.means,
                            measurevar = "grips",
                            withinvars = "trial",
                            betweenvars = "group",
                            idvar = "id")

dfTRIALg$trial       <- as.numeric(dfTRIALg$trial)

pp <-  ggplot(dfTRIAL, aes(x =trial, y = grips)) +
  geom_point(data = dfTRIALg, aes(shape = group), alpha = 0.3, color = 'black') +
  geom_line(data = dfTRIAL, size =1, color = pal[4]) +
  geom_ribbon(aes(ymin=grips-se__, ymax=grips+se__), fill = pal[4], alpha = 0.3, )+
  ylab('Number of Grips')+
  xlab('Trial') +
  scale_y_continuous(expand = c(0, 0),  limits = c(10.5,15.05),  breaks=c(seq.int(11,15, by = 1))) +
  scale_x_continuous(expand = c(0, 0),  limits = c(0,25),  breaks=c(seq.int(1,25, by = 2))) +
  scale_shape_manual(name="Group", labels=c("Lean", "Obese"), values = c(1, 2, 18)) +
  theme_bw()

pp + html_theme + theme(legend.position=c(.9,.88))
plt = pp + averaged_theme + theme(legend.position=c(.9,.88))

```
```{r INST_saveFIG, include = FALSE, warning=FALSE}
cairo_pdf('figures/Figure_Instrumental_trial.pdf')
print(plt)
dev.off()
```

### Pavlvovian-Instrumental Transfer (PIT) Task 
Mobilized effort = Area under the curve of the force exerted exceeding the delivery threshold during Pavlovian cue presentation
```{r PIT, echo=F, results='hide', message=FALSE, warning=FALSE}

mf = formula(AUC ~ condition*group*hungry  + (condition|id) + (1|trialxcondition))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
bmod_full = brm(bf(mf, hu ~ 1), family = hurdle_gaussian, stanvars = stanvars, data=PIT.clean, prior =  c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = ""), prior(logistic(0, 0.5), class = "Intercept", dpar = "hu")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstan', threads = threading(4)) # a lot to unwind here.. 1) custom gaussian hurdle cause zero-inflated continous data more details here: https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html 2) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 3) we need to sample priors and save parameters for computing BF 

#lmer to compare
fmod_full = lmer(mf , data = PIT.clean, REML=F, control = control)

```


```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling
param = mcmc_plot(object = bmod_full,  pars=c("b_.*o","b_.*y"), type ="areas") 

trace = mcmc_plot(object = bmod_full,  pars=c("b_.*o","b_.*y"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", stat = "median", group = "group", binwidth = 1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagPIT <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagPIT, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
# check response fit -> capture better the bimodal distrib
# residual ... could be better but at least it's MUCH better than simple gaussian see lmx[1] ... this is just catastrophic..
```


```{r PIT_res, include=FALSE, cache=F}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))



full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "b_hu_Intercept", "prior_sigma"))

#contrasts
ems = emmeans(bmod_full, pairwise ~condition:group )

PIT_lean = c(-1,1,0,0) # CS+>CS- Lean
PIT_obe = c(0,0,-1,1) # CS+>CS- Obese 
con_inter = contrast(ems$emmeans, method = list("CS+ > CS-: Obese - CS+ > CS-: Lean" = PIT_obe - PIT_lean)) #diff of diff


inter_tab = describe_posterior(con_inter,
                   estimate = "median", dispersion = TRUE,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

con_ob = contrast(ems$emmeans, method = list("CS+ > CS-: Obese" = PIT_obe)) #PIT ob
con_lean =contrast(ems$emmeans, method = list("CS+ > CS-: Lean" = PIT_lean), ) #PIT lean
con_group = rbind(con_ob, con_lean); 

con_tab = describe_posterior(con_group,
                   estimate = "median",  dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))


# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------


# fmod_inter = update(fmod_full,  ~ .-condition:group) #evaluate interaction
# fmod_cond = update(fmod_full,  ~ .-condition) #evaluate condition
# fmod_group =  update(fmod_full, ~ .-group) #evaluate group
# 
# # p-value from bootstrap distribution
# LRT_inter = PBmodcomp(fmod_full, fmod_inter, nsim = 500, seed = 123, cl=cores) 
# LRT_cond = PBmodcomp(fmod_full, fmod_cond, nsim = 500, seed = 123, cl=cores) 
# LRT_group = PBmodcomp(fmod_inter, fmod_group, nsim = 500, seed = 123, cl=cores)
# 
# ems = emmeans(fmod_full, pairwise ~condition:group)
# #con = contrast(ems$emmeans, method = list(PIT_obe - PIT_lean)) #diff of diff
# con_ob = contrast(ems$emmeans, method = list(PIT_obe)) #PIT ob
# con_lean = contrast(ems$emmeans, method = list(PIT_lean)) #PIT lean
# conF = rbind(con_ob, con_lean)

# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Mobilized effort (a.u.)", file = "tmp/temp4.html", transform = NULL,  rm.terms = "hu_Intercept")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r PIT_tab}
print(paste("Bayesian general linear mixed model (hurdle gaussian family with a identity link) (estimated using MCMC sampling with" ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict Mobilized Effort (AUC) with condition, group and hungry (formula: AUC ~ condition * group * hungry). The model included condition, id and trialxcondition as random effects (formula: list(~condition | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00) and student_t (location = 0.00, scale = 133.90) distributions for beta and sd respectively"))

full_tab

report[c(8,9)]


tables <- list.clean(readHTMLTable("tmp/temp4.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble(); 


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)

```
\
Post-hoc contrasts 

```{r}
inter_tab

con_tab
```
\

#### Plot {-}

```{r PIT_plot, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="A) Posterior distribution by group. B) Highest density interval (90% HDI) for the interaction condition by group."}

# plot HDI
dfdraws = bmod_full %>%
    spread_draws(`b_condition:group`, `b_condition:hungry` )

HDI_group_PIT = plotHDI( dfdraws$`b_condition:group` , credMass = .90, binSize = 100, Title = "") + theme_bw(); 

HDI_hunger_PIT = plotHDI( dfdraws$`b_condition:hungry` , credMass = .90, binSize = 100, Title = "") + theme_bw()

#plot estimated means from posterior distribution from the model draws


dfdraws2 =  bmod_full %>%
     emmeans(~ condition:group) %>%
     gather_emmeans_draws() 

CSp = subset(dfdraws2, condition ==1); CSm = subset(dfdraws2, condition ==-1); diff= CSp; diff$.value = CSp$.value - CSm$.value


pp = diff %>%
    ggplot(aes(x = as_factor(group) , y = .value,  fill = as_factor(group))) +
    geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    #geom_point(position = "jitter") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    ylab('Mobilized effort (\u0394 CS+ > CS-)')+
    xlab('')+
    scale_fill_manual(values=c("1" = pal[6],"-1"=pal[1]), guide="none") +
    scale_color_manual( values=c("1" = pal[6],"-1"=pal[1]), guide="none") +
    scale_x_discrete(labels=c("Lean", "Obese")) +
    theme_bw()

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figurePIT <- ggarrange(plt_bayes_html, HDI_group_PIT,
                    labels = c("A", "B"),
                    ncol = 2)
figurePIT

#labels = c("1"="Obese", "-1"="Lean")

#plot estimated means from raw data

# dfH <- summarySEwithin(PIT.means,
#                        measurevar = "AUC",
#                        withinvars = "condition",
#                        betweenvars = "group",
#                        idvar = "id")
#
# pp = dfH %>%
#   ggplot(aes(x = group,  fill = condition)) +
#   stat_dist_halfeye(aes(dist = "norm", arg1 = AUC, arg2 =se), position = "dodge", alpha = 0.6) +
#   ylab('Mobilized effort (a.u.) \n Baseline corrected')+
#   xlab('')+
#   scale_fill_manual(name = "",  labels=c("CS-", "CS+"),values=c("1" = pal[2],"-1"=pal[1])) +
#   scale_color_manual(name = "", labels=c("CS-", "CS+"), values=c("1" = pal[2],"-1"=pal[1]))  +
#   scale_x_discrete(labels=c("Lean \u2800\u2800\u2800\u2800\u2800\u2800", "Obese \u2800\u2800\u2800\u2800\u2800\u2800")) +
#   theme_bw()

# pp + html_theme + theme(axis.ticks.x = element_blank(), legend.position=c(.9,.2),legend.key.size = unit(0.7, "cm"))
# plt = pp + averaged_theme + theme(axis.ticks.x = element_blank(), legend.position=c(.9,.2),legend.key.size = unit(0.7, "cm"))

```


```{r PIT_time, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="Mobilized effort for each condition and group over trials."}


# PLOT OVERTIME

labels <- c("-1" = "Lean", "1" = "Obese")

pp <- ggplot(PIT.p, aes(x = as.numeric(trial), y = AUC,
                        color = condition,
                        fill  = condition))+
  geom_line(alpha = .5, size = 1, show.legend = F) +
  geom_ribbon(aes(ymax = AUC + se, ymin = AUC - se),  alpha=0.4) +
  geom_point() +
  ylab('Mobilized effort (a.u.)')+
  xlab('Trial')+
  scale_color_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
                     values = c("1"= pal[2], '-1'= pal[1])) +
  scale_fill_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
                    values = c("1"= pal[2], '-1'= pal[1])) +
  scale_y_continuous(expand = c(0, 0),  limits = c(50,200),  breaks=c(seq.int(50,200, by = 50))) +
  scale_x_continuous(expand = c(0, 0),  limits = c(0,15),  breaks=c(seq.int(1,15, by = 2))) +
  theme_bw() +
  facet_wrap(~group, labeller=labeller(group =labels))


pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.3, "cm"))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.8, "cm"), axis.text.x = element_text(size = 16))



# bmod_time = update(bmod_full,  ~ .+as.factor(trialxcondition)) #evaluate interaction
# 
# df =  bmod_time %>%
#      emmeans(~ condition:group:trialxcondition) 
# 
# 
# 
# bayes_plt = as_tibble(df) %>%
#     ggplot(aes(x = trialxcondition, y = emmean,  fill =as.factor(condition))) +
#     #geom_point(position = "jitter") +
#     geom_smooth(method=loess, se = T,inherit.aes = T) + 
#     #stat_slab(.width = c(0.50, 0.95),position="dodge", alpha=0.5) +
#     #stat_pointinterval(.width = c(0.50, 0.95),position="dodge") +
#     ylab('Mobilized effort (a.u.) \n Baseline corrected')+
#     xlab('')+
#     scale_fill_manual(values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     scale_color_manual( values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     #scale_x_discrete(labels=c("CS+", "CS-")) +
#     theme_bw() + facet_wrap(~group, labeller=labeller(group =labels))

```

```{r PITsaveFIG, include = FALSE, warning=FALSE}
cairo_pdf('figures/Figure_PIT_time.pdf')
print(plt)
dev.off()

cairo_pdf('figures/Figure_PIT.pdf')
print(figurePIT)
dev.off()
```


# Hedonic Reactivity Test 
Perceived liking = how pleasant is the liquid solution rated (0-100, with repetitions)   &   condition = Milshake or Tasteless   &   intensity = difference on how intense the liquid solution were rated (mean(Milshake) - mean(Tasteless)) &   familiarity = difference on how familiar the liquid solution were rated (mean(Milshake) - mean(Tasteless))
```{r HED, include=FALSE, cache=F}

mf = formula(perceived_liking ~ condition*group*hungry  + int + fam + (condition|id) + (1|trialxcondition))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
bmod_full = brm(bf(mf, hu ~ 1), family = hurdle_gaussian, stanvars = stanvars, data=HED, prior =  c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = ""), prior(logistic(0, 0.5), class = "Intercept", dpar = "hu")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstan', threads = threading(4))# a lot to unwind here.. 1)  custom gaussian hurdle cause zero-inflated continous data 2) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 3) we need to sample priors and save parameters for computing BF #this one is a big longer, so seat tight

#lmer to compare
fmod_full = lmer(mf , data = HED, REML=F, control = control)

```

```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*y","b_.*int", "b_.*fam"), type ="areas")

trace = mcmc_plot(object = bmod_full,  pars =c("b_.*o","b_.*y","b_.*int", "b_.*fam"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", stat ="median", group = "group", binwidth = 0.1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagHED <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagHED, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
# check response fit -> capture much better the bimodal distribution !
# residual ~kinda ok #but again at least it's MUCH better than simple gaussian see lmx[1] ...

```


```{r HED_res, include=FALSE, cache=F}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))



full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "b_hu_Intercept", "prior_sigma"))


# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------


# fmod_cond = update(fmod_full,  ~ .-condition) #evaluate condition
# 
# # p-value from bootstrap distribution
# LRT_cond = PBmodcomp(fmod_full, fmod_cond, nsim = 500, seed = 123, cl=cores) 
# 


# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Perceived liking", file = "tmp/temp5.html", transform = NULL)

report = capture.output(sexit(bmod_full, ci=.9))

```

```{r HED_tab}
print(paste("Bayesian general linear mixed model (hurdle gaussian family with a identity link) (estimated using MCMC sampling with", chains," chains of", niter, " iterations and a warmup of", warm, ") to predict Perceived Liking with condition, intensity, familiarity, group and hungry (formula: perceived_liking ~ intensity + familiarity + condition * group * hungry). The model included condition, id and trialxcondition as random effects (formula: list(~condition | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00) and student_t (location = 0.00, scale = 31.7) distributions for beta and sd respectively"))

full_tab

report[5]


tables <- list.clean(readHTMLTable("tmp/temp5.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+2):(length(full_tab$Parameter)+6),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)


```
\

#### Plot {-}
```{r HED_plot, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="A) Posterior distribution by taste solution. B) Highest density interval (90% HDI) of the posterior distribution difference for the perceived liking between milkshake and tasteless."}


dfdraws = bmod_full %>%
    spread_draws(`b_condition` )


HDI_HED = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw() + html_theme  


dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>%
    ggplot(aes(x = as_factor(condition) , y = .value,  fill = as_factor(condition))) +
    #geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    labs(x = "", y = "Perceived liking", title = "") + 
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
    scale_x_discrete(labels=c("Tasteless", "Milkshake")) +
    scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
    theme_bw()

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figureHED <- ggarrange(plt_bayes_html, HDI_HED,
                    labels = c("A", "B"),
                    ncol = 2)
figureHED



# AVERAGED EFFECT
dfH <- summarySEwithin(HED.means,
                       measurevar = "liking",
                       withinvars = "condition",
                       idvar = "id")

dfH$cond <- ifelse(dfH$condition == "1", -0.25, 0.25)
HED.means$cond <- ifelse(HED.means$condition == "1", -0.25, 0.25)
HED.means <- HED.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
                                  grouping = interaction(id, cond))


pp <- ggplot(HED.means, aes(x = cond, y = liking,
                            fill = as.factor(condition), color = as.factor(condition),)) +
  geom_point(data = dfH, alpha = 0.5) +
  geom_line(aes(x = condjit, group = id, y = liking), alpha = .3, size = 0.5, color = 'gray') +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
  geom_point(aes(x = condjit, shape = as.factor(group)), alpha = .3) +
  geom_crossbar(data = dfH, aes(y = liking, ymin=liking-se, ymax=liking+se), width = 0.2 , alpha = 0.1)+
  ylab('Perceived liking') +
  xlab('Taste') +
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
  scale_x_continuous(labels=c("Tasteless", "Milkshake"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("1"= pal[3], "-1"=pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"=pal[3], "-1"=pal[1]), guide = 'none') +
  scale_shape_manual(name="Group", labels=c("Lean", "Obese"), values = c(1, 2)) +
  theme_bw()

plt <- pp + averaged_theme
#pp + html_theme 
```


```{r HED_time, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="Perceived liking for each condition over trials.",  out.width = "60%"}

# OVERTIME
HED.t <- summarySEwithin(HED,
                         measurevar = "perceived_liking",
                         withinvars = c("trialxcondition","condition"),
                         idvar = "id")

HED.tg <- summarySEwithin(HED,
                          measurevar = "perceived_liking",
                          withinvars = c("trialxcondition","condition"),
                          betweenvars = 'group',
                          idvar = "id")


# plot
pp <- ggplot(HED.t, aes(x = as.numeric(trialxcondition), y = perceived_liking,
                        color =condition, fill = condition)) +
  geom_point(data = HED.tg, aes(shape=group), alpha = 0.5) +
  geom_point(data = HED.t) +
  geom_line(alpha = .7, size = 1) +
  geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
  ylab('Perceived liking')+
  xlab('Trial') +
  scale_shape_manual(name="Group", labels=c("Lean", "Obese"), values = c(1, 2)) +
  scale_color_manual(labels = c('Pleasant', 'Neutral'), name = "",
                     values = c( "1" =pal[3], '-1' =pal[1])) +
  scale_fill_manual(labels = c('Pleasant', 'Neutral'), name = "",
                    values = c( "1" =pal[3], '-1'=pal[1])) +
  scale_y_continuous(expand = c(0, 0),  limits = c(0,100),  breaks=c(seq.int(0,100, by = 20))) +
    scale_x_continuous(expand = c(0, 0),  limits = c(0,21),  breaks=c(seq.int(1,21, by = 2))) +
  guides(color=guide_legend(override.aes=list(fill=c(pal[3], pal[1]), color=c(pal[3], pal[1]))))+
  theme_bw()


plt <- pp + averaged_theme + guides(shape = guide_legend(order = 1)) + theme(legend.margin=margin(0,0,0,0), legend.box = "horizontal", legend.key.size = unit(0.4, "cm"), axis.text.x = element_text(size = 16), legend.position = c(0.8, 0.915))
pp + html_theme + guides(shape = guide_legend(order = 1)) + theme(legend.margin=margin(0,0,0,0), legend.box = "horizontal", legend.key.size = unit(0.4, "cm"), legend.position = c(0.8, 0.915))

```
```{r HED_saveFIG, include = FALSE, warning=FALSE, results='hide'}
cairo_pdf('figures/Figure_HED_time.pdf')
print(plt)
dev.off()

cairo_pdf('figures/Figure_HED.pdf')
print(figureHED)
dev.off()
```
\

#### Packages {-}
```{r, warning=F}
report::report_packages()

# aaronpeikert/repro@devel #repro, crsh/papaja@devel,knitr, afex #aov_car/lmer, emmeans #emmeans, parallel #detectCores, tidyverse ##ggplot/dplyr/plyr/tidyr, car #densityPlot, lspline # lspline, JWileymisc #egtable, kableExtra #kable_styling, glmnet #cv.glmnet, ggthemes #theme_fivethirtyeight,  MBESS #pes_ci, sjPlot #tab_model/plot_model, Rmisc #SummarySEwithin, janitor #row_to_names, rlist #list.clean, sessioninfo #sessioninfo, stringr #str_list, XML #readHTMLtable, bayestestR #bayesfactor_models, cmdstanr #multithead, ggpubr::ggarrange	#	Arrange Multiple ggplots, tidybayes #spread draws]  
```
```{bash, include=F}
cp OBIWAN_T0.html index.html #this is just to change the output name for github
```
