<<<<<<< HEAD
#contrasts
# emmip(bmod_full, condition~intervention) to visualize
#
# ems = emmeans(bmod_full, ~condition|intervention)
# con_inter = contrast(ems, interaction = "pairwise", by = NULL)
#
#
# inter_tab = describe_posterior(con_inter,
#                    estimate = "median", dispersion = TRUE,
#                    ci = .9, ci_method = "hdi",
#                    bf_prior = bmod_full, diagnostic = "Rhat",
#                    test = c("p_direction", "bf"))
# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------
# fmod_cond = update(fmod_full,  ~ .-condition) #evaluate condition
# # p-value from bootstrap distribution
# LRT_cond = PBmodcomp(fmod_full, fmod_cond, nsim = 500, seed = 123, cl=cores)
# -------------------------------------- Regression table summary --------------------------------------
tab_model(bmod_full, show.p = F,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Perceived liking", file = "tmp/temp6.html", transform = NULL,  rm.terms = "hu_Intercept")
report = capture.output(sexit(bmod_full, ci=.9))
print(paste("Bayesian general linear mixed model (hurdle gaussian family with a identity link) (estimated using MCMC sampling with", chains," chains of", niter, " iterations and a warmup of", warm, ") to predict Perceived Liking with condition, intervention, session, age, gender, BMI_V1, hungry, GLP_diff and reelin_diff (formula: perceived_liking ~ condition * intervention * session + age + gender + BMI_V1 + hungry + GLP_diff + reelin_diff + int + fam). The model included condition, session, id and trialxcondition as random effects (formula: list(~condition | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00) and student_t (location = 0.00, scale = 31.7) distributions for beta and sd respectively"))
full_tab
report[5]
tables <- list.clean(readHTMLTable("tmp/temp6.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble();
tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+3):(length(full_tab$Parameter)+7),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)
tables <- list.clean(readHTMLTable("tmp/temp6.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble();
tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+2):(length(full_tab$Parameter)+5),1:2]);
tmp
tables <- list.clean(readHTMLTable("tmp/temp6.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble();
tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
tmp
pander::pander(tmp)
# plot HDI
dfdraws = bmod_full %>%
spread_draws(`b_condition` )
HDI_HED = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw()
#plot estimated means from posterior distribution from the model draws
dfdraws2 =  bmod_full %>%
emmeans(~ condition) %>%
gather_emmeans_draws()
pp = dfdraws2 %>% #diff
ggplot(aes(x = as.factor(condition) , y = .value,  fill = as.factor(condition))) +
#geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
#geom_point(position = "jitter") +
stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
labs(x = "", y = "Perceived liking", title = "") +
scale_fill_manual(values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
scale_color_manual( values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
scale_x_discrete(labels=c("Tasteless", "Milkshake")) +
scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
theme_bw()
plt_bayes_html = pp + html_theme
plt_bayes = pp + averaged_theme
figureHED <- ggarrange(plt_bayes_html, HDI_HED,
labels = c("A", "B"),
ncol = 2)
# plot HDI
dfdraws = bmod_full %>%
spread_draws(`b_condition` )
HDI_HED = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw()
#plot estimated means from posterior distribution from the model draws
dfdraws2 =  bmod_full %>%
emmeans(~ condition) %>%
gather_emmeans_draws()
pp = dfdraws2 %>% #diff
ggplot(aes(x = as.factor(condition) , y = .value,  fill = as.factor(condition))) +
#geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
#geom_point(position = "jitter") +
stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
labs(x = "", y = "Perceived liking", title = "") +
scale_fill_manual(values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
scale_color_manual( values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
scale_x_discrete(labels=c("Tasteless", "Milkshake")) +
scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
theme_bw()
plt_bayes_html = pp + html_theme
plt_bayes = pp + averaged_theme
figureHED <- ggarrange(plt_bayes_html, HDI_HED,
labels = c("A", "B"),
ncol = 2)
figureHED
dfH <- summarySEwithin(HED.means,
measurevar = "perceived_liking",
withinvars = c("condition","session"),
idvar = "id")
dfH$cond <- ifelse(dfH$condition == "1", -0.25, 0.25)
HED.means$cond <- ifelse(HED.means$condition == "1", -0.25, 0.25)
HED.means <- HED.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
grouping = interaction(id, cond))
pp <- ggplot(HED.means, aes(x = cond, y = perceived_liking,
fill = as.factor(condition), color = as.factor(condition))) +
geom_point(data = dfH, alpha = 0.5) +
geom_line(aes(x = condjit, group = id, y = perceived_liking), alpha = .3, size = 0.5, color = 'gray') +
geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
geom_point(aes(x = condjit, shape = as.factor(intervention)), alpha = .3,) +
geom_crossbar(data = dfH, aes(y = perceived_liking, ymin=perceived_liking-se, ymax=perceived_liking+se), width = 0.2 , alpha = 0.1)+
ylab('Perceived liking') +
xlab('Taste') +
scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
scale_x_continuous(labels=c("Pleasant", "Neutral"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
scale_fill_manual(values=c("1"= pal[3], "-1"=pal[1]), guide = 'none') +
scale_color_manual(values=c("1"=pal[3], "-1"=pal[1]), guide = 'none') +
scale_shape_manual(name="Intervention", labels=c("Placebo", "Liraglutide"), values = c(1, 2)) +
theme_bw()+ facet_wrap(~session, labeller=labeller(session = labels))
pp + html_theme +theme(legend.position=c(.96,.94))
plt = pp + averaged_theme +theme(legend.position=c(.96,.94))
pp <- ggplot(HED.p, aes(x = as.numeric(trial), y = perceived_liking,
=======
<<<<<<< HEAD
pp <- ggplot(PIT.p, aes(x = as.numeric(trial), y = AUC,
color = condition,
fill  = condition))+
geom_point(data = PIT.group, aes(shape = intervention), alpha = 0.3, color = 'black') +
=======
fill  = condition))+
geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F)
HED.group
head(HED.group)
head(PIT.group)
ggplot(PIT.p, aes(x = as.numeric(trial), y = AUC,
color = condition,
fill  = condition))+
geom_point(data = PIT.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = AUC + se, ymin = AUC - se),  alpha=0.4) +
geom_point()
ggplot(PIT.p, aes(x = as.numeric(trial), y = AUC,
color = condition,
fill  = condition))+
geom_point(data = PIT.group, aes(shape = intervention, color = condition), alpha = 0.3) +
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = AUC + se, ymin = AUC - se),  alpha=0.4) +
geom_point() +
ylab('Mobilized effort (a.u.)')+
xlab('Trial')+
scale_color_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
<<<<<<< HEAD
values = c("1"= pal[2], '-1'= pal[1])) +
scale_fill_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
values = c("1"= pal[2], '-1'= pal[1])) +
=======
values = c("1"= pal[6], '-1'= pal[1])) +
scale_fill_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
values = c("1"= pal[6], '-1'= pal[1])) +
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
scale_y_continuous(expand = c(0, 0),  limits = c(50,200),  breaks=c(seq.int(50,200, by = 50))) +
scale_x_continuous(expand = c(0, 0),  limits = c(0,15),  breaks=c(seq.int(1,15, by = 2))) +
scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
theme_bw() +
facet_wrap(~session, labeller=labeller(session =labels))
<<<<<<< HEAD
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.3, "cm"))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.8, "cm"), axis.text.x = element_text(size = 16))
pp + html_theme + theme(strip.background = element_rect(fill="white"))
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.3, "cm"))
pp <- ggplot(PIT.p, aes(x = as.numeric(trial), y = AUC,
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
color = condition,
fill  = condition))+
geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
geom_point() +
ylab('Perceived Liking')+
xlab('Trial')+
scale_color_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1' =pal[1])) +
scale_fill_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1'=pal[1])) +
scale_y_continuous(expand = c(0, 0),  limits = c(0,100),  breaks=c(seq.int(0,100, by = 20))) +
scale_x_continuous(expand = c(0, 0),  limits = c(0,21),  breaks=c(seq.int(1,21, by = 2))) +
guides(color=guide_legend(override.aes=list(fill=c(pal[3], pal[1]), color=c(pal[3], pal[1]))))+
scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
theme_bw() +
facet_wrap(~session, labeller=labeller(session =labels))
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.3, "cm"))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.8, "cm"), axis.text.x = element_text(size = 16))
dfH <- summarySEwithin(HED.means,
measurevar = "perceived_liking",
withinvars = c("condition","session"),
idvar = "id")
dfH$cond <- ifelse(dfH$condition == "1", -0.25, 0.25)
HED.means$cond <- ifelse(HED.means$condition == "1", -0.25, 0.25)
HED.means <- HED.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
grouping = interaction(id, cond))
pp <- ggplot(HED.means, aes(x = cond, y = perceived_liking,
fill = as.factor(condition), color = as.factor(condition))) +
geom_point(data = dfH, alpha = 0.5) +
geom_line(aes(x = condjit, group = id, y = perceived_liking), alpha = .3, size = 0.5, color = 'gray') +
geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
geom_point(aes(x = condjit, shape = as.factor(intervention)), alpha = .3,) +
geom_crossbar(data = dfH, aes(y = perceived_liking, ymin=perceived_liking-se, ymax=perceived_liking+se), width = 0.2 , alpha = 0.1)+
ylab('Perceived liking') +
xlab('Taste') +
scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
scale_x_continuous(labels=c("Pleasant", "Neutral"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
scale_fill_manual(values=c("1"= pal[3], "-1"=pal[1]), guide = 'none') +
scale_color_manual(values=c("1"=pal[3], "-1"=pal[1]), guide = 'none') +
scale_shape_manual(name="Intervention", labels=c("Placebo", "Liraglutide"), values = c(1, 2)) +
theme_bw()+ facet_wrap(~intervention)
pp
inter
mdl.hf = aov_car(data = inter, HF_inter ~ intervention + BMI_diff + age + Error(id), factorize = F, type = "II", anova_table = list(correction = "GG", es = "pes"))
res = nice(mdl.hf, MSE=F); ref_grid(mdl.hf)  #triple check everything is centered at 0
#calculate Partial eta-squared and its 90 % CI for each effect
PES.hf = pes_ci(data = inter, HF_inter ~ intervention + BMI_diff + age + Error(id), conf.level = .90, factorize = FALSE, anova.type = "II", epsilon="none") ;
mdl.hf.emms = emmeans(mdl.hf, pairwise ~ intervention)
res$p.value = as.numeric(res$p.value)
res$p.value = ifelse(res$p.value < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",res$p.value), "</span>"),  paste("<span>" ,sprintf("%.3f",res$p.value), "</span>"))
res$F = unlist(str_split(gsub("[^0-9.,-]", "", res$F), ","));res$pes = unlist(str_split(gsub("[^0-9.,-]", "", res$pes), ","));
res$`90% CI` = paste(sprintf("%.3f",PES.hf[,2]), "-", sprintf("%.3f",PES.hf[,3]))
res$p.value[1]= "<span style=\" font-weight: bold;    \" >\u003C 0.001</span>"
#res$pes[c(5,7,8)]= c("\u003C 0.001")
colnames(res)[3:5] = c( paste("F(", res$df[1], ")", sep=""),"&eta;<sub>p</sub><sup>2</sup>", "p")
res[c(1,4,6,3,5)]  %>% kbl(digits = 2, escape = F,row.names = F)  %>%
kable_styling(latex_options = "striped", position = "center", full_width = F)
#print('PES: intervention: Overall higher weight loss for treament (Liraglutide) group')
#PES.weight[1,]
mod = lm(HF_inter ~ intervention + BMI_diff + age, data = inter)
x = plot_model(mod, type = "diag")
x[c(2,3,4,1)]
#check assumptions
# PLOT OVERTIME
pp <- ggplot(HED.p, aes(x = as.numeric(trial), y = perceived_liking,
color = condition,
fill  = condition))+
geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
geom_point() +
ylab('Perceived Liking')+
xlab('Trial')+
<<<<<<< HEAD
=======
scale_color_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
values = c("1"= pal[2], '-1'= pal[1])) +
scale_fill_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
values = c("1"= pal[2], '-1'= pal[1])) +
scale_y_continuous(expand = c(0, 0),  limits = c(50,200),  breaks=c(seq.int(50,200, by = 50))) +
scale_x_continuous(expand = c(0, 0),  limits = c(0,15),  breaks=c(seq.int(1,15, by = 2))) +
=======
ggplot(HED.p, aes(x = as.numeric(trial), y = perceived_liking,
color = condition,
fill  = condition))+
geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
geom_point() +
ylab('Perceived Liking')+
xlab('Trial')+
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
scale_color_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1' =pal[1])) +
scale_fill_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1'=pal[1])) +
scale_y_continuous(expand = c(0, 0),  limits = c(0,100),  breaks=c(seq.int(0,100, by = 20))) +
scale_x_continuous(expand = c(0, 0),  limits = c(0,21),  breaks=c(seq.int(1,21, by = 2))) +
guides(color=guide_legend(override.aes=list(fill=c(pal[3], pal[1]), color=c(pal[3], pal[1]))))+
<<<<<<< HEAD
=======
theme_bw()
scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
theme_bw() +
facet_wrap(~session, labeller=labeller(session =labels))
HED.p
head(HED.p)
ggplot(HED.p, aes(x = as.numeric(trial), y = perceived_liking,
color = condition,
fill  = condition))+
geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
geom_point() +
ylab('Perceived Liking')+
xlab('Trial')+
scale_color_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1' =pal[1])) +
scale_fill_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1'=pal[1])) +
scale_y_continuous(expand = c(0, 0),  limits = c(0,100),  breaks=c(seq.int(0,100, by = 20))) +
scale_x_continuous(expand = c(0, 0),  limits = c(0,21),  breaks=c(seq.int(1,21, by = 2))) +
guides(color=guide_legend(override.aes=list(fill=c(pal[3], pal[1]), color=c(pal[3], pal[1]))))+
scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
theme_bw() +
facet_wrap(~session, labeller=labeller(session =labels))
pp <- ggplot(HED.p, aes(x = as.numeric(trial), y = perceived_liking,
color = condition,
fill  = condition))+
geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
geom_line(alpha = .5, size = 1, show.legend = F) +
geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
geom_point() +
ylab('Perceived Liking')+
xlab('Trial')+
scale_color_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1' =pal[1])) +
scale_fill_manual(labels = c('Pleasant', 'Neutral'), name = "",
values = c( "1" =pal[3], '-1'=pal[1])) +
scale_y_continuous(expand = c(0, 0),  limits = c(0,100),  breaks=c(seq.int(0,100, by = 20))) +
scale_x_continuous(expand = c(0, 0),  limits = c(0,21),  breaks=c(seq.int(1,21, by = 2))) +
guides(color=guide_legend(override.aes=list(fill=c(pal[3], pal[1]), color=c(pal[3], pal[1]))))+
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
theme_bw() +
facet_wrap(~session, labeller=labeller(session =labels))
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.3, "cm"))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.8, "cm"), axis.text.x = element_text(size = 16))
<<<<<<< HEAD
##We see here the base difference between Placebo VS Liraglutide BUT it's the same for both sessions so .. no effect of the treatment really XXXX
# bmod_time = update(bmod_full,  ~ .+as.factor(trialxcondition)) #evaluate interaction
=======
<<<<<<< HEAD
=======
bmod_full
full_tab
ems = emmeans(bmod_full, pairwise ~condition:intervention)
ems
full_tab
HED_pla = c(-1,1,0,0) # Pleasant>Neutral Pla
HED_lira = c(0,0,-1,1) # Pleasant>Neutral Lira
con_inter = contrast(ems$emmeans, method = list("Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo" = HED_lira - HED_pla)) #diff of diff
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
ems = emmeans(bmod_full, pairwise ~condition:intervention:session)
ems
HED_pla_pre = c(-1,1,0,0,0,0,0,0) # Pleasant>Neutral Pla
HED_lira_pre = c(0,0,-1,1,0,0,0,0) # Pleasant>Neutral Lira
con_inter_pre = contrast(ems$emmeans, method = list("[PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo" = HED_lira_pre - HED_pla_pre)) #diff of diff
con_inter_pre
HED_pla_post = c(0,0,0,0,-1,1,0,0) # Pleasant>Neutral Pla
HED_lira_post = c(0,0,0,0,0,0,-1,1) # Pleasant>Neutral Lira
con_inter_post = contrast(ems$emmeans, method = list("[POST] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo" = HED_lira_post - HED_pla_post)) #diff of diff
contrast(ems$emmeans, method = list("[POST] - [PRE]" = con_inter_post - con_inter_pre)) #diff of diff
list("[POST] - [PRE]" = con_inter_post - con_inter_pre))
list("[POST] - [PRE]" = con_inter_post - con_inter_pre)
ist("[PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo" = HED_lira_pre - HED_pla_pre)
list("[PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo" = HED_lira_pre - HED_pla_pre)
lsmeans(bmod_full, ~condition*intervention|session)
lsm = lsmeans(bmod_full, ~condition*intervention|session)
contrast(lsm, interaction = "pairwise")
lsm = lsmeans(bmod_full, ~condition*intervention*session)
contrast(lsm, interaction = "pairwise")
lsm = lsmeans(bmod_full, ~condition*intervention|session)
con_inter = contrast(lsm, interaction = "pairwise")
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
con_inter
emmeans(contrast(lsm, interaction = "pairwise"))
lsm = lsmeans(bmod_full, ~condition*intervention*session)
contrast(lsm)
contrast(lsm, interaction = "pairwise")
emmip(lsm, type ~ condition | intervention)
emmip(bmod_full, type ~ condition | intervention)
pairs(lsm, simple = "session")
lsm = lsmeans(bmod_full, ~condition*intervention*session)
pairs(lsm, simple = "session")
lsm = lsmeans(bmod_full, ~condition*intervention|session)
contrast(lsm, interaction = c( "consec"), by = NULL)
contrast(lsm, interaction = c( "consec"), by = session)
contrast(lsm, interaction = c( "consec"), by = "session")
contrast(lsm, interaction = c( "pairwise"), by = "session")
contrast(lsm, by = "session")
contrast(lsm, interaction = c( "pairwise"), by = "session")
contrast(lsm, interaction = c( "consec"), by = "session")
contrast(lsm, interaction = c( "consec"))
contrast(lsm, interaction = c( "consec"), by = NULL)
7.69-12.53
contrast(lsm, by = NULL)
contrast(lsm, interaction = c( "pairwise"), by = NULL)
12.53-7.69
emmip(noise.lm, condition~intervention|session)
emmip(bmod_full, condition~intervention|session)
emmip(bmod_full, condition|session*intervention)
emmip(bmod_full, condition~intervention*session)
emmip(bmod_full, session~intervention|condition)
emmip(bmod_full, session*intervention*condition)
lsmeans(bmod_full, ~session*intervention|condition)
lsm = lsmeans(bmod_full, ~session*intervention|condition)
contrast(lsm, interaction = "pairwise")
lsm = lsmeans(bmod_full, ~condition*intervention|session)
con_inter = contrast(lsm, interaction = "pairwise")
con_inter
contrast(lsm, con_inter)
contrast(con_inter)
contrast(con_inter, pairwise)
contrast(con_inter, interaction = "pairwise")
con_inter = contrast(lsm, interaction = "pairwise")
con_inter
as_tibble(con_inter)
contrast(lsm, interaction = "pairwise", by = NULL)
12.53  -7.69
contrast(lsm, interaction = "consec", by = NULL)
con_inter
lsm = lsmeans(bmod_full, ~condition*intervention*session)
contrast(lsm, interaction = "pairwise", by = "session")
contrast(lsm,  by = "session")
contrast(lsm)
lsm = lsmeans(bmod_full, ~condition*intervention|session)
lsmeans(bmod_full, ~condition*intervention|session)
lsmeans(bmod_full, ~condition|session*intervention)
lsm = lsmeans(bmod_full, ~condition|session*intervention)
lsmeans(bmod_full, ~condition|session*intervention)
contrast(lsm, interaction = "pairwise")
contrast(lsm, interaction = "pairwise", by = NULL)
coef(contrast(lsm, interaction = "pairwise", by = NULL))
coef(contrast(lsm, interaction = "consec", by = NULL))
coef(contrast(lsm, interaction = "consec", by = "session"))
(HED_lira_pre - HED_pla_pre) - (HED_lira_post - HED_pla_post)
con_inter = contrast(ems$emmeans, method = list("[POST] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo" = (HED_lira_pre - HED_pla_pre) - (HED_lira_post - HED_pla_post))) #diff of diff
con_inter
contrast(ems$emmeans, method = list("([POST] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo) - ([PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo)" = (HED_lira_pre - HED_pla_pre) - (HED_lira_post - HED_pla_post))) #diff of diff
con_inter = contrast(ems$emmeans, method = list("([POST] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo) - ([PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo)" = (HED_lira_pre - HED_pla_pre) - (HED_lira_post - HED_pla_post))) #diff of diff
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
con_inter = contrast(ems$emmeans, method = list("([POST] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo) - ([PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo)" = (HED_pla_pre - HED_lira_pre) - (HED_pla_post - HED_lira_post))) #diff of diff
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
con_inter = contrast(ems$emmeans, method = list("([POST] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo) - ([PRE] Pleasant > Neutral: Liraglutide - Pleasant > Neutral: Placebo)" =  (HED_pla_post - HED_lira_post)-(HED_pla_pre - HED_lira_pre))) #diff of diff
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
emmip(bmod_full, condition~|intervention)
emmip(bmod_full, condition|intervention)
emmip(bmod_full, condition~intervention)
emmeans(bmod_full, ~condition|intervention)
contrast(ems, interaction = "pairwise", by = NULL)
contrast(ems, interaction = "pairwise")
ems
ems = emmeans(bmod_full, ~condition|intervention)
ems
contrast(ems, interaction = "pairwise")
contrast(ems, interaction = "pairwise", by = NULL)
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
con_inter = contrast(ems, interaction = "pairwise")
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
con_inter = contrast(ems, interaction = "pairwise", by = NULL)
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
full_tab
describe_posterior(con_inter,
estimate = "median", dispersion = TRUE,
ci = .9, ci_method = "hdi",
bf_prior = bmod_full, diagnostic = "Rhat",
test = c("p_direction", "bf"))
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
intern  <- automate_load_data(intern, read.csv, stringsAsFactors = T)
medic    <- automate_load_data(medic, read.csv, stringsAsFactors = T)
PAV      <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST     <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT      <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED      <- automate_load_data(HED, read.csv, stringsAsFactors = T)
HED_fMRI <- automate_load_data(HED_fMRI, read.csv, stringsAsFactors = T)
<<<<<<< HEAD
x = session_info();  opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE) # set F for all
## we recommend running this is a fresh R session or restarting your current session
#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#install_cmdstan()
# check_git(); check_make(); check_docker() #check if installed
sessio = session_info(); #opts_chunk$set(echo = F, message=F, warning=F) # set echo F for all
niter = 500; warm = 100; chains = 4; cores = 4; nsim = 10000 # number of iterations (to change if you want to quick check and warmups #or also parallel::detectCores()/2)
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = cores);  #remove scientific notation # remove warnings #set contrasts to sum !
#cl = parallel::detectCores()/2
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
#emm_options(pbkrtest.limit = 8000) #increase repetitions limit for frequentist stats
source('R/plots.R', echo=F)# plot specification
source('R/utils.R', echo=F)# useful functions
panderOptions('knitr.auto.asis', FALSE) #remove auto styling
labels <- c("-1" = "Pre", "1" = "Post")#for plots
# Look at R/clean.R (listed in the YAML) which does all the preprocessing for more info
# If you are unsure weather or not you have `git` `make` & `docker`.
# check_git()
# check_make()
# check_docker()
#subset only obese
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 228 REALLY hated the solution and thus didn't "do" the conditioning)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 228))
# list2env(dflist, envir=.GlobalEnv)
#center covariates paste0(names(PAV), collapse="','")
medic$ageF = medic$age; medic$weightLoss = -(medic$BMI_diff); medic$bmi1 = medic$BMI_V1; medic$dif_interv = medic$Date_diff #keep uncentered for descriptive stats + reverse BMI_diff so it in terms of actual weight loss and not weight gain
biomed <- c('age','Date_diff','BW_diff','BMI_diff','WC_diff','Insulin_diff','X2.AG_diff','reelin_diff','MCP_diff','TNFalpha_diff','GLP_diff','Ghrelin_diff','Glu_diff','HOMA_IR_diff', 'AEA_diff', 'OEA_diff', 'PEA_diff', 'BMI_V1')
medic = medic %>% group_by %>% mutate_at(biomed, scale)
#remove outliers from biomedical (+- 3 SD)
df_dict <- data.frame(variable = biomed, out_low = rep(-3,length(biomed)),  out_high = rep(3,length(biomed)))
for (var in df_dict$variable) {
medic[[var]][medic[[var]] < df_dict[df_dict$variable == var, ]$out_low | medic[[var]] > df_dict[df_dict$variable == var, ]$out_high] <- NaN}
#merge with medic
tables = tables[-length(tables)]; # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, medic, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry',  'piss', 'id', 'session')], by = c("id", 'session'), all.x=TRUE)
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
#center covariates
numer <- c('thirsty','hungry')
dflist <- lapply(mget(tables),function(x) x %>% group_by %>% mutate_at(numer, scale))
list2env(dflist, envir=.GlobalEnv)
covariate = c(biomed, numer)
# prepro RT PAV -----------------------------------------------------------
# get times in milliseconds
PAV$RT    <- PAV$RT * 1000
#Preprocessing
PAV$condition <- droplevels(PAV$condition, exclude = "Baseline")
acc_bef = mean(PAV$ACC, na.rm = TRUE) # 0.87
full = length(PAV$RT)
##shorter than 100ms and longer than 3sd+mean
PAV.clean <- filter(PAV, RT >= 100) # min RT is
PAV.clean <- ddply(PAV.clean, .(id, session), transform, RTm = mean(RT), RTsd = sd(RT))
PAV.clean <- filter(PAV.clean, RT <= RTm+3*RTsd)
# calculate the dropped data in the preprocessing
clean = length(PAV.clean$RT)
dropped = full-clean
(dropped*100)/full #13.26754
# clean PAV --------------------------------------------------------------
PAV = PAV.clean
# define as.factors
fac <- c("id", "trial", "condition", "session", "intervention","trialxcondition", "gender"); PAV[fac] <- lapply(PAV[fac], factor)
#revalue all catego
PAV$session = PAV$session = ifelse(PAV$session == "second", -1, 1)
#as.factor(revalue(PAV$session, c(second="-1", third="1"))) #change value of session
PAV$condition = ifelse(PAV$condition == "CSminus", -1, 1)
PAV$intervention = ifelse(PAV$intervention == "0", -1, 1)  #change value of intervention
#PAV$condition = as.factor(revalue(PAV$condition, c(CSminus="-1", CSplus="1")));
PAV.means <- aggregate(PAV[,c(covariate, "weightLoss", "ageF",  "bmi1", "liking", "RT")] , by = list(PAV$id, PAV$condition,PAV$session,PAV$intervention, PAV$gender), FUN = 'mean',na.action = na.omit)
colnames(PAV.means) <- c('id','condition','session','intervention', 'gender', covariate,"weightLoss", "ageF", "bmi1", "liking", "RT")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values fot 2 participant 262 and 232)
PAV.means$thirsty[is.na(PAV.means$thirsty)] <- 0 ; PAV.means$hungry[is.na(PAV.means$hungry)] <- 0
# clean INST --------------------------------------------------------------
INST$Trial = as.numeric(INST$trial)
x = lspline(INST$Trial, 5); INST$Trial1 = x[,1]; INST$Trial2 = x[,2];
# define as.factors
fac <- c("id", "session", "intervention", "gender"); INST[fac] <- lapply(INST[fac], factor)
#revalue all catego
INST$gender = INST$gender = ifelse(INST$gender == "0", -1, 1)
INST$session = INST$session = ifelse(INST$session == "second", -1, 1)
#as.factor(revalue(PAV$session, c(second="-1", third="1"))) #change value of session
INST$intervention = ifelse(INST$intervention == "0", -1, 1)  #change value of intervention
# INST$session = as.factor(revalue(INST$session, c(second="0", third="1"))) #change value of session
# get the averaged dataset
INST.means <- aggregate(INST[,c(covariate, "grips")] , by = list(INST$id,INST$trial, INST$session,INST$intervention, INST$gender), FUN = 'mean',na.action = na.omit)
colnames(INST.means) <- c('id','trial','session','intervention', 'gender', covariate, "grips")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values for 3 participant 239, 258, 231)
INST.means$thirsty[is.na(INST.means$thirsty)] <- 0 ; INST.means$hungry[is.na(INST.means$hungry)] <- 0
INST.means$Trial = as.numeric(INST.means$trial)
x = lspline(INST.means$Trial, 5); INST.means$Trial1 = x[,1]; INST.means$Trial2 = x[,2];
dfTrial = ddply(INST,.(trial,session),summarise,grips=mean(grips)); dfTrial$Trial = scale(as.numeric(dfTrial$trial))
dfTrial$phasis = ifelse(dfTrial$Trial >	-1.07212710 , "1", "0")
dfTrial$T2 = ifelse(dfTrial$Trial > 0, dfTrial$Trial^2, -dfTrial$Trial^2)
# clean PIT --------------------------------------------------------------
# define as.factors
fac <- c("id", "trial", "condition", "session", "intervention","trialxcondition", "gender"); PIT[fac] <- lapply(PIT[fac], factor)
PIT.base =  subset(PIT, condition == 'BL'); PIT.csp =  subset(PIT, condition == 'CSplus'); PIT.csm =  subset(PIT, condition == 'CSminus')
PIT.csp = PIT.csp %>% arrange(desc(id)); PIT.csm =PIT.csm %>% arrange(desc(id)); PIT.base =PIT.base %>% arrange(desc(id)) #order by id
#PIT.csp$AUC = PIT.csp$AUC - PIT.base$AUC; PIT.csm$AUC = PIT.csm$AUC - PIT.base$AUC
PIT.clean = rbind(PIT.csp, PIT.csm) #bind together
#revalue all catego
PIT.clean$condition = ifelse(PIT.clean$condition == "CSminus", -1, 1)
PIT.clean$gender = PIT.clean$gender = ifelse(PIT.clean$gender == "0", -1, 1)
PIT.clean$session = PIT.clean$session = ifelse(PIT.clean$session == "second", -1, 1)
PIT.clean$intervention = ifelse(PIT.clean$intervention == "0", -1, 1)
PIT.means <- aggregate(PIT.clean[,c(covariate, "AUC")] , by = list(PIT.clean$id, PIT.clean$condition,PIT.clean$session,PIT.clean$intervention, PIT.clean$gender), FUN = 'mean',na.action = na.omit)
colnames(PIT.means) <- c('id','condition','session','intervention', 'gender', covariate, "AUC")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values fot 2 participant 229 and 238)
PIT.means$thirsty[is.na(PIT.means$thirsty)] <- 0 ; PIT.means$hungry[is.na(PIT.means$hungry)] <- 0
PIT.p <- summarySEwithin(PIT.clean,
measurevar = "AUC",
withinvars = c("trialxcondition","condition", "session"),
idvar = "id")
PIT.p$trial <- as.numeric(PIT.p$trialxcondition)
PIT.p = select(PIT.p, c('trial', 'N' , 'AUC', 'sd', 'se', 'ci', 'condition',"session"))
PIT.p$condition <- relevel(PIT.p$condition, "1") # Make MilkShake first
PIT.group <- summarySEwithin(PIT.clean,
measurevar = "AUC",
withinvars = c("trialxcondition","condition", "session"),
betweenvars = "intervention",
idvar = "id")
PIT.group$trial <- as.numeric(PIT.group$trialxcondition)
PIT.group = select(PIT.group, c('trial', 'N' , 'AUC', 'sd', 'se', 'ci', 'condition', 'intervention',"session"))
PIT.group$condition <- relevel(PIT.group$condition, "1") # Make MilkShake first
# clean HED --------------------------------------------------------------
#create and center int covariate
HED$lik = HED$perceived_liking #rename
dfl = ddply(HED,.(id,condition,session),summarise, fam=mean(perceived_familiarity), int=mean(perceived_intensity));
dfi = subset(dfl, condition  =="MilkShake"); dfi$int = dfl$int[dfl$condition  =="MilkShake"] -dfl$int[dfl$condition  =="Empty"];  dfi$fam = dfl$fam[dfl$condition  =="MilkShake"] -dfl$fam[dfl$condition  =="Empty"]; dfi$int = scale(dfi$int); dfi$fam = scale(dfi$fam); dfi = dfi[-c(2)]
HED = merge(HED, dfi, by = c("id", "session"))
# define as.factors
fac <- c("id", "trial", "condition", "session", "intervention","trialxcondition", "gender"); HED[fac] <- lapply(HED[fac], factor)
#revalue all catego
HED$session = as.factor(revalue(HED$session, c(second="0", third="1"))) #change value of session
HED$condition = as.factor(revalue(HED$condition, c(Empty="-1", MilkShake="1")));#HED$condition <- factor(HED$condition, levels = c("1", "-1"))#change value of condition
HED.means <- aggregate(HED[,c(covariate, "fam", "int", "lik")] , by = list(HED$id, HED$condition,HED$session,HED$intervention, HED$gender), FUN = 'mean', na.action = na.omit)
colnames(HED.means) <- c('id','condition','session','intervention', 'gender', covariate, "fam", "int", "lik")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values fr 1 participant 217)
HED.means$thirsty[is.na(HED.means$thirsty)] <- 0 ; HED.means$hungry[is.na(HED.means$hungry)] <- 0
# ALL ---------------------------------------------------------------------
#factorize ID
tables <- c("PAV.means","PIT.means","HED.means")
dflist <- lapply(mget(tables),function(x)facID(x))
list2env(dflist, envir=.GlobalEnv)
save(PAV.means, file = "data/PAV.Rdata")
save(INST.means, file = "data/INST.Rdata")
save(PIT.means, file = "data/PIT.Rdata")
save(HED.means, file = "data/HED.Rdata")
#create df for AFNI
dfHED = HED.means
dfHED[is.na(dfHED)] <- 0
save(dfHED, file = "data/HED_fmri.Rdata")
# internHED = subset(intern, phase ==5)
# dfx = x = Reduce(function(x,y) merge(x = x, y = y, by = "id"),
#                  list(df, internHED, info)); dfx[is.na(dfx)] <- 0
# x = Reduce(function(x,y) merge(x = x, y = y, by = c("id","session")),
#            list(dfl, dfm, dfx))
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
#
# df =  bmod_time %>%
#      emmeans(~ condition:session:trialxcondition)
#
#
#
# bayes_plt = as_tibble(df) %>%
#     ggplot(aes(x = trialxcondition, y = emmean,  fill =as.factor(condition))) +
#     #geom_point(position = "jitter") +
#     geom_smooth(method=loess, se = T,inherit.aes = T) +
#     #stat_slab(.width = c(0.50, 0.95),position="dodge", alpha=0.5) +
#     #stat_pointinterval(.width = c(0.50, 0.95),position="dodge") +
#     ylab('Mobilized effort (a.u.) \n Baseline corrected')+
#     xlab('')+
#     scale_fill_manual(values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     scale_color_manual( values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     #scale_x_discrete(labels=c("CS+", "CS-")) +
#     theme_bw() + facet_wrap(~session, labeller=labeller(session =labels))
plt
pp + html_theme + theme(strip.background = element_rect(fill="white"))
pp + html_theme + theme(strip.background = element_rect(fill="white"), +theme(legend.position=c(.96,.94)))
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.position=c(.96,.94))
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.position=c(1.,.94))
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.position=c(1.2,.94))
pp
strip_theme <- theme_bw(base_size = 24, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 24, face = "bold"),
strip.background = element_rect(color="white", fill="white", linetype="solid")
legend.title  = element_text(size = 8),
legend.text  = element_text(size = 6),
legend.key.size = unit(0.2, "cm"),
legend.key = element_rect(fill = "transparent", colour = "transparent"),
panel.grid.major.x = element_blank() ,
panel.grid.major.y = element_line(size=.2, color="lightgrey") ,
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 18),
axis.title.y = element_text(size =18),
axis.line = element_line(size = 0.5),
panel.border = element_blank())
strip_theme <- theme_bw(base_size = 24, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 24, face = "bold"),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
legend.title  = element_text(size = 8),
legend.text  = element_text(size = 6),
legend.key.size = unit(0.2, "cm"),
legend.key = element_rect(fill = "transparent", colour = "transparent"),
panel.grid.major.x = element_blank() ,
panel.grid.major.y = element_line(size=.2, color="lightgrey") ,
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 18),
axis.title.y = element_text(size =18),
axis.line = element_line(size = 0.5),
panel.border = element_blank())
pp + strip_theme + theme(strip.background = element_rect(fill="white"))
pp + strip_theme + theme(strip.background = element_rect(fill="white"), legend.position="topright")
pp + strip_theme + theme(strip.background = element_rect(fill="white"), legend.position="top")
pp + strip_theme + theme(strip.background = element_rect(fill="white"), legend.position="left")
pp + strip_theme + theme(strip.background = element_rect(fill="white"), legend.position="bottom")
pp + strip_theme + theme(strip.background = element_rect(fill="white"), legend.position="right")
pp + strip_theme + theme(strip.background = element_rect(fill="white"), theme(legend.justification = "top"))
pp + strip_theme + theme(strip.background = element_rect(fill="white"), legend.justification = "top")
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.justification = "top", axis.text.x = element_text(size = 16))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), axis.text.x = element_text(size = 16), legend.justification = "top")
pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.justification = "top", legend.position="right", axis.text.x = element_text(size = 16))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), axis.text.x = element_text(size = 16), legend.justification = "top", legend.position="right")
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
intern  <- automate_load_data(intern, read.csv, stringsAsFactors = T)
medic    <- automate_load_data(medic, read.csv, stringsAsFactors = T)
PAV      <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST     <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT      <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED      <- automate_load_data(HED, read.csv, stringsAsFactors = T)
HED_fMRI <- automate_load_data(HED_fMRI, read.csv, stringsAsFactors = T)
x = session_info();  opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE) # set F for all
=======
x = session_info();  opts_chunk$set(warning = FALSE, message = FALSE) # set F for all
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
## we recommend running this is a fresh R session or restarting your current session
#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#install_cmdstan()
# check_git(); check_make(); check_docker() #check if installed
<<<<<<< HEAD
sessio = session_info(); #opts_chunk$set(echo = F, message=F, warning=F) # set echo F for all
<<<<<<< HEAD
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 10000 # number of iterations (to change if you want to quick check and warmups (BUT chains and BF might be really unstable if you have less than 20'000 iter (4x5000) ) #or also parallel::detectCores()/2)
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = cores)  #remove scientific notation # remove warnings #set contrasts to sum ! #remove scientific notation # remove warnings #set contrasts to sum !
=======
niter = 500; warm = 100; chains = 4; cores = 4; nsim = 10000 # number of iterations (to change if you want to quick check and warmups #or also parallel::detectCores()/2)
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = cores);  #remove scientific notation # remove warnings #set contrasts to sum !
=======
#May I suggest running `repro::automate()`?
#This will create a `Dockerfile` & `Makefile` based on every RMarkdown in this folder and the special yamls in them. date: "`r format(Sys.time(), '%d %B, %Y')`"
#add ENV DEBIAN_FRONTEND=noninteractive to DOCKERFILE
niter = 500; warm = 100; chains = 4; cores = 4; nsim = 10000 # number of iterations (to change if you want to quick check and warmups (BUT chains and BF might be really unstable if you have less than 20'000 iter (4x5000) ) #or also parallel::detectCores()/2)
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = cores)  #remove scientific notation # remove warnings #set contrasts to sum ! #remove scientific notation # remove warnings #set contrasts to sum !
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
#cl = parallel::detectCores()/2
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
#emm_options(pbkrtest.limit = 8000) #increase repetitions limit for frequentist stats
source('R/plots.R', echo=F)# plot specification
source('R/utils.R', echo=F)# useful functions
panderOptions('knitr.auto.asis', FALSE) #remove auto styling
labels <- c("-1" = "Pre", "1" = "Post")#for plots
# Look at R/clean.R (listed in the YAML) which does all the preprocessing for more info
<<<<<<< HEAD
# If you are unsure weather or not you have `git` `make` & `docker`.
# check_git()
# check_make()
# check_docker()
=======
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
#subset only obese
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 228 REALLY hated the solution and thus didn't "do" the conditioning)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 228))
# list2env(dflist, envir=.GlobalEnv)
#center covariates paste0(names(PAV), collapse="','")
medic$ageF = medic$age; medic$weightLoss = -(medic$BMI_diff); medic$bmi1 = medic$BMI_V1; medic$dif_interv = medic$Date_diff #keep uncentered for descriptive stats + reverse BMI_diff so it in terms of actual weight loss and not weight gain
biomed <- c('age','Date_diff','BW_diff','BMI_diff','WC_diff','Insulin_diff','X2.AG_diff','reelin_diff','MCP_diff','TNFalpha_diff','GLP_diff','Ghrelin_diff','Glu_diff','HOMA_IR_diff', 'AEA_diff', 'OEA_diff', 'PEA_diff', 'BMI_V1')
medic = medic %>% group_by %>% mutate_at(biomed, scale)
#remove outliers from biomedical (+- 3 SD)
df_dict <- data.frame(variable = biomed, out_low = rep(-3,length(biomed)),  out_high = rep(3,length(biomed)))
for (var in df_dict$variable) {
medic[[var]][medic[[var]] < df_dict[df_dict$variable == var, ]$out_low | medic[[var]] > df_dict[df_dict$variable == var, ]$out_high] <- NaN}
#merge with medic
tables = tables[-length(tables)]; # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, medic, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry',  'piss', 'id', 'session')], by = c("id", 'session'), all.x=TRUE)
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
#center covariates
numer <- c('thirsty','hungry')
dflist <- lapply(mget(tables),function(x) x %>% group_by %>% mutate_at(numer, scale))
list2env(dflist, envir=.GlobalEnv)
covariate = c(biomed, numer)
# prepro RT PAV -----------------------------------------------------------
# get times in milliseconds
PAV$RT    <- PAV$RT * 1000
#Preprocessing
PAV$condition <- droplevels(PAV$condition, exclude = "Baseline")
acc_bef = mean(PAV$ACC, na.rm = TRUE) # 0.87
full = length(PAV$RT)
##shorter than 100ms and longer than 3sd+mean
PAV.clean <- filter(PAV, RT >= 100) # min RT is
PAV.clean <- ddply(PAV.clean, .(id, session), transform, RTm = mean(RT), RTsd = sd(RT))
PAV.clean <- filter(PAV.clean, RT <= RTm+3*RTsd)
# calculate the dropped data in the preprocessing
clean = length(PAV.clean$RT)
dropped = full-clean
(dropped*100)/full #13.26754
# clean PAV --------------------------------------------------------------
PAV = PAV.clean
# define as.factors
fac <- c("id", "trial", "condition", "session", "intervention","trialxcondition", "gender"); PAV[fac] <- lapply(PAV[fac], factor)
#revalue all catego
PAV$session = PAV$session = ifelse(PAV$session == "second", -1, 1)
#as.factor(revalue(PAV$session, c(second="-1", third="1"))) #change value of session
PAV$condition = ifelse(PAV$condition == "CSminus", -1, 1)
PAV$gender = ifelse(PAV$gender == "0", -1, 1)
PAV$intervention = ifelse(PAV$intervention == "0", -1, 1)  #change value of intervention
#PAV$condition = as.factor(revalue(PAV$condition, c(CSminus="-1", CSplus="1")));
PAV.means <- aggregate(PAV[,c(covariate, "weightLoss", "ageF",  "bmi1", "liking", "RT")] , by = list(PAV$id, PAV$condition,PAV$session,PAV$intervention, PAV$gender), FUN = 'mean',na.action = na.omit)
colnames(PAV.means) <- c('id','condition','session','intervention', 'gender', covariate,"weightLoss", "ageF", "bmi1", "liking", "RT")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values fot 2 participant 262 and 232)
<<<<<<< HEAD
#PAV.means$thirsty[is.na(PAV.means$thirsty)] <- 0 ; PAV.means$hungry[is.na(PAV.means$hungry)] <- 0
=======
<<<<<<< HEAD
PAV.means$thirsty[is.na(PAV.means$thirsty)] <- 0 ; PAV.means$hungry[is.na(PAV.means$hungry)] <- 0
=======
#PAV.means$thirsty[is.na(PAV.means$thirsty)] <- 0 ; PAV.means$hungry[is.na(PAV.means$hungry)] <- 0
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
# clean INST --------------------------------------------------------------
INST$Trial = as.numeric(INST$trial)
x = lspline(INST$Trial, 5); INST$Trial1 = x[,1]; INST$Trial2 = x[,2];
# define as.factors
fac <- c("id", "session", "intervention", "gender"); INST[fac] <- lapply(INST[fac], factor)
#revalue all catego
INST$gender = INST$gender = ifelse(INST$gender == "0", -1, 1)
INST$session = INST$session = ifelse(INST$session == "second", -1, 1)
#as.factor(revalue(PAV$session, c(second="-1", third="1"))) #change value of session
INST$intervention = ifelse(INST$intervention == "0", -1, 1)  #change value of intervention
# INST$session = as.factor(revalue(INST$session, c(second="0", third="1"))) #change value of session
# get the averaged dataset
INST.means <- aggregate(INST[,c(covariate, "grips")] , by = list(INST$id,INST$trial, INST$session,INST$intervention, INST$gender), FUN = 'mean',na.action = na.omit)
colnames(INST.means) <- c('id','trial','session','intervention', 'gender', covariate, "grips")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values for 3 participant 239, 258, 231)
<<<<<<< HEAD
#INST.means$thirsty[is.na(INST.means$thirsty)] <- 0 ; INST.means$hungry[is.na(INST.means$hungry)] <- 0
=======
<<<<<<< HEAD
INST.means$thirsty[is.na(INST.means$thirsty)] <- 0 ; INST.means$hungry[is.na(INST.means$hungry)] <- 0
=======
#INST.means$thirsty[is.na(INST.means$thirsty)] <- 0 ; INST.means$hungry[is.na(INST.means$hungry)] <- 0
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
INST.means$Trial = as.numeric(INST.means$trial)
x = lspline(INST.means$Trial, 5); INST.means$Trial1 = x[,1]; INST.means$Trial2 = x[,2];
dfTrial = ddply(INST,.(trial,session),summarise,grips=mean(grips)); dfTrial$Trial = scale(as.numeric(dfTrial$trial))
dfTrial$phasis = ifelse(dfTrial$Trial >	-1.07212710 , "1", "0")
dfTrial$T2 = ifelse(dfTrial$Trial > 0, dfTrial$Trial^2, -dfTrial$Trial^2)
# clean PIT --------------------------------------------------------------
# define as.factors
fac <- c("id", "trial", "condition", "session", "intervention","trialxcondition", "gender"); PIT[fac] <- lapply(PIT[fac], factor)
PIT.base =  subset(PIT, condition == 'BL'); PIT.csp =  subset(PIT, condition == 'CSplus'); PIT.csm =  subset(PIT, condition == 'CSminus')
PIT.csp = PIT.csp %>% arrange(desc(id)); PIT.csm =PIT.csm %>% arrange(desc(id)); PIT.base =PIT.base %>% arrange(desc(id)) #order by id
#PIT.csp$AUC = PIT.csp$AUC - PIT.base$AUC; PIT.csm$AUC = PIT.csm$AUC - PIT.base$AUC
PIT.clean = rbind(PIT.csp, PIT.csm) #bind together
#revalue all catego
PIT.clean$condition = ifelse(PIT.clean$condition == "CSminus", -1, 1)
PIT.clean$gender = PIT.clean$gender = ifelse(PIT.clean$gender == "0", -1, 1)
PIT.clean$session = PIT.clean$session = ifelse(PIT.clean$session == "second", -1, 1)
PIT.clean$intervention = ifelse(PIT.clean$intervention == "0", -1, 1)
PIT.means <- aggregate(PIT.clean[,c(covariate, "AUC")] , by = list(PIT.clean$id, PIT.clean$condition,PIT.clean$session,PIT.clean$intervention, PIT.clean$gender), FUN = 'mean',na.action = na.omit)
colnames(PIT.means) <- c('id','condition','session','intervention', 'gender', covariate, "AUC")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values fot 2 participant 229 and 238)
<<<<<<< HEAD
#PIT.means$thirsty[is.na(PIT.means$thirsty)] <- 0 ; PIT.means$hungry[is.na(PIT.means$hungry)] <- 0
=======
<<<<<<< HEAD
PIT.means$thirsty[is.na(PIT.means$thirsty)] <- 0 ; PIT.means$hungry[is.na(PIT.means$hungry)] <- 0
=======
#PIT.means$thirsty[is.na(PIT.means$thirsty)] <- 0 ; PIT.means$hungry[is.na(PIT.means$hungry)] <- 0
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
PIT.p <- summarySEwithin(PIT.clean,
measurevar = "AUC",
withinvars = c("trialxcondition","condition", "session"),
idvar = "id")
PIT.p$trial <- as.numeric(PIT.p$trialxcondition)
PIT.p = select(PIT.p, c('trial', 'N' , 'AUC', 'sd', 'se', 'ci', 'condition',"session"))
PIT.p$condition <- relevel(PIT.p$condition, "1") # Make MilkShake first
PIT.group <- summarySEwithin(PIT.clean,
measurevar = "AUC",
withinvars = c("trialxcondition","condition", "session"),
betweenvars = "intervention",
idvar = "id")
PIT.group$trial <- as.numeric(PIT.group$trialxcondition)
PIT.group = select(PIT.group, c('trial', 'N' , 'AUC', 'sd', 'se', 'ci', 'condition', 'intervention',"session"))
PIT.group$condition <- relevel(PIT.group$condition, "1") # Make MilkShake first
# clean HED --------------------------------------------------------------
# define as.factors
fac <- c("id", "trial", "condition", "session", "intervention","trialxcondition", "gender"); HED[fac] <- lapply(HED[fac], factor)
# recode as contr.sum dummy coding
HED$intervention = ifelse(HED$intervention == "0", 1,-1) #change value of group
HED$gender = ifelse(HED$gender == "0", -1, 1) #change value of gender
HED$condition = ifelse(HED$condition == "MilkShake", 1,-1); #change value of condition
HED$session = ifelse(HED$session == "second", 1,-1); #change value of condition
# create Intensity and Familiarity diff
bs = ddply(HED, .(id, condition), summarise, int = mean(perceived_intensity, na.rm = TRUE), fam = mean(perceived_familiarity, na.rm = TRUE))
Empty = subset(bs, condition == "-1"); Milkshake = subset(bs, condition == "1"); diff = Empty;
diff$int = Milkshake$int - Empty$int; diff$fam = Milkshake$fam - Empty$fam;
HED = merge(x = HED, y = diff[ , c("int", "fam", 'id')], by = "id", all.x=TRUE)
#center covariates
numer <- c("fam", "int")
HED = HED %>% group_by %>% mutate_at(numer, scale)
HED$intensity = HED$int; HED$familiarity = HED$fam
HED.means <- aggregate(HED[,c(covariate, "fam", "int", "perceived_liking")] , by = list(HED$id, HED$condition,HED$session,HED$intervention, HED$gender), FUN = 'mean', na.action = na.omit)
colnames(HED.means) <- c('id','condition','session','intervention', 'gender', covariate, "fam", "int", "perceived_liking")
#imput mean (0) for the two covariate (MAR) so we can get BF (missing values fr 1 participant 217)
<<<<<<< HEAD
=======
<<<<<<< HEAD
HED.means$thirsty[is.na(HED.means$thirsty)] <- 0 ; HED.means$hungry[is.na(HED.means$hungry)] <- 0
=======
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
#HED.means$thirsty[is.na(HED.means$thirsty)] <- 0 ; HED.means$hungry[is.na(HED.means$hungry)] <- 0
HED.p <- summarySEwithin(HED,
measurevar = "perceived_liking",
withinvars = c("trialxcondition","condition", "session"),
idvar = "id")
HED.p$trial <- as.numeric(HED.p$trialxcondition)
HED.p = select(HED.p, c('trial', 'N' , 'perceived_liking', 'sd', 'se', 'ci', 'condition',"session"))
HED.p$condition <- relevel(HED.p$condition, "1") # Make MilkShake first
HED.group <- summarySEwithin(HED,
measurevar = "perceived_liking",
withinvars = c("trialxcondition","condition", "session"),
betweenvars = "intervention",
idvar = "id")
HED.group$trial <- as.numeric(HED.group$trialxcondition)
HED.group = select(HED.group, c('trial', 'N' , 'perceived_liking', 'sd', 'se', 'ci', 'condition', 'intervention',"session"))
HED.group$condition <- relevel(HED.group$condition, "1") # Make MilkShake first
<<<<<<< HEAD
=======
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
# ALL ---------------------------------------------------------------------
#factorize ID
tables <- c("PAV.means","PIT.means","HED.means")
dflist <- lapply(mget(tables),function(x)facID(x))
list2env(dflist, envir=.GlobalEnv)
save(PAV.means, file = "data/PAV.Rdata")
save(INST.means, file = "data/INST.Rdata")
save(PIT.means, file = "data/PIT.Rdata")
save(HED.means, file = "data/HED.Rdata")
#create df for AFNI
dfHED = HED.means
dfHED[is.na(dfHED)] <- 0
save(dfHED, file = "data/HED_fmri.Rdata")
# internHED = subset(intern, phase ==5)
# dfx = x = Reduce(function(x,y) merge(x = x, y = y, by = "id"),
#                  list(df, internHED, info)); dfx[is.na(dfx)] <- 0
# x = Reduce(function(x,y) merge(x = x, y = y, by = c("id","session")),
#            list(dfl, dfm, dfx))
#
# tables = c('x')
# numer <- c("thirsty", "hungry",  "piss", "OEA", "PEA","X2.AG","AEA","Leptin",  "Resistin","adiponectin","MCP","TNFalpha","reelin","glucagon", "Ghrelin","obestatin","GLP1","insulin","Fast_glu","BMI_t1", "bmi_diff")
# dflist <- lapply(mget(tables),function(x) x %>% group_by %>% mutate_at(numer, scale))
# list2env(dflist, envir=.GlobalEnv); x$age = x$age_Z
#
# dfHED = select(x, -c(age_Z, bmi1, bmi_dif, task, phase, idXsession, BMI_t2, group))
# dfHED$session = as.factor(revalue(as.factor(dfHED$session), c("second"="0", "third"="1"))); dfHED1 = dfHED;  dfHED2 = dfHED; dfHED1$condition = "1"; dfHED2$condition = "-1"; dfHED = rbind(dfHED1, dfHED2); dfHED[is.na(dfHED)] <- 0
#
# save(dfHED, file = "data/HED_fmri.Rdata")
#
# create df for weight loss
df = subset(PAV.means, session == "1"); df = subset(df, condition == "1")
df$AGE = df$ageF; df$BMI = df$bmi1 ; df$GENDER = df$gender; df$INTERVENTION = df$intervention
<<<<<<< HEAD
=======
<<<<<<< HEAD
df$intervention = ifelse(df$intervention == 0, -1, 1) #change value of intervention
df$gender = ifelse(df$gender == 0, -1, 1) #change value of gender
df$INTERVENTION = as.factor(revalue(as.factor(df$INTERVENTION), c("0"="Placebo", "1"="Liraglutide")))#using pav.means but oculd be any other
df$GENDER = as.factor(revalue(as.factor(df$GENDER), c("0"="Men", "1"="Women")))
=======
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
#df$intervention = ifelse(df$intervention == -1, -1, 1) #change value of intervention
#df$gender = ifelse(df$gender == 0, -1, 1) #change value of gender
df$INTERVENTION = as.factor(revalue(as.factor(df$INTERVENTION), c("-1"="Placebo", "1"="Liraglutide")))#using pav.means but oculd be any other
df$GENDER = as.factor(revalue(as.factor(df$GENDER), c("-1"="Men", "1"="Women")))
<<<<<<< HEAD
=======
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
med <- gather(df, "feature", "n", 8:22)
#biomed = numer[3:14];
dfmed = na.omit(medic[,c('intervention',biomed[3:14])]) #create df for var selec
#inter score for fmri Plots
diffPRE = subset(HED_fMRI, session == 'pre') ; diffPOST = subset(HED_fMRI, session == 'post')
inter = diffPRE; inter$OFC_inter =  diffPOST$OFC_score - diffPRE$OFC_score; inter$HF_inter =  diffPOST$HF_score - diffPRE$HF_score
inter$id = as.factor(inter$id); inter$intervention = as.factor(inter$intervention)
inter = filter(inter, id %notin% c(246)) #remove huge outlier because it biases the whole further results on mediation and weigthloss -> you can check it ou via:
# ggplot(inter, aes(x= BMI_diff, y=intervention, label=id))+
#   geom_point() +geom_text(aes(label=id),hjust=1, vjust=0)
weightloss = inter$BMI_diff; #reverse in terms of wight loss not weigth gain
ind <- sapply(inter, is.numeric)
inter[ind] <- lapply(inter[ind], scale)
inter$Intervention = as.numeric(inter$intervention); inter$HF  = as.vector(inter$HF_inter); inter$`Weight Loss` = -as.vector(weightloss) #reverse to have it in positive terms
<<<<<<< HEAD
# Model
mf1 = formula(grips ~ trial*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (session|id) + (1|trial)) # LINEAR FIT
mf2 = formula(grips ~  lspline(trial,5)*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (session|id) + (1|trial)) # PIECEWISE REGRESSION WITH SPLINE AT 5
# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
linmod = brm(mf1, data=INST, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4))  # a lot to unwind here..  1) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
splinemod = update(linmod, formula. = mf2)
=======
<<<<<<< HEAD
HED$perceived_familiarity
HED$int
HED$fam
mf = formula(perceived_liking ~ condition*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + int + fam + (condition*session|id) + (1|trialxcondition))
# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
bmod_full = brm(bf(mf, hu ~ 1), family = hurdle_gaussian, stanvars = stanvars, data=HED, prior =  c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = ""), prior(logistic(0, 0.5), class = "Intercept", dpar = "hu")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstan', threads = threading(4))# a lot to unwind here.. 1)  custom gaussian hurdle cause zero-inflated continous data 2) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 3) we need to sample priors and save parameters for computing BF #this one is a big longer, so seat tight
#lmer to compare
fmod_full = lmer(mf , data = HED, REML=F, control = control)
bmod_full
fmod_full = lmer(mf , data = HED, REML=F, control = control)
summary(fmod_full)
mcmc_plot(object = bmod_full,  pars=c("b_.*o","b_.*y"), type ="areas")
pp_check(bmod_full, nsamples = 10)
=======
# Model
mf = formula(weightLoss ~ intervention + gender + age + GLP_diff + reelin_diff  + (1|id))
# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
# STAN is a probabilistic programming language that allows you to get full Bayesian statistical inference with MCMC sampling.
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
#problem here!!
#lmer to compare
fmod_full = lm(update(mf, ~.- (1|id)) , data = df)
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 10000 # number of iterations (to
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
mcmc_plot(object = bmod_full, pars =c("b_.*en", "b_.*ge"), type ="trace")
niter
niter = 1000
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
niter =2000
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
mcmc_plot(object = bmod_full, pars =c("b_.*en", "b_.*ge"), type ="trace")
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = 1,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
mcmc_plot(object = bmod_full, pars =c("b_.*en", "b_.*ge"), type ="trace")
mcmc_plot(object = bmod_full, pars =c("b_.*en", "b_.*ge"), type ="areas")
mcmc_plot(object = bmod_full, type ="areas")
bmod_full
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 10), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = 1,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 3), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = 1,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
mcmc_plot(object = bmod_full, type ="areas")
bmod_full = brm(mf, data=df, family = gaussian, sample_prior = T, save_pars = save_pars(all = TRUE), chains = 1,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
mcmc_plot(object = bmod_full, type ="trace")
bmod_full
bmod_full = brm(mf, data=df, family = gaussian, sample_prior = T, save_pars = save_pars(all = TRUE), chains = 1,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4), control = list(adapt_delta = 0.99)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF
mcmc_plot(object = bmod_full, type ="trace")
>>>>>>> 35dc91fe44a50b55b81e91aa8ebd1f392c49d136
>>>>>>> 70dd7549694c9e18fbac10623599b18f065fa8c6
