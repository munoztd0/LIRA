load("~/paramC.RData")
load("~/paramB.RData")
load("~/paramA.RData")
load("~/dfsim.RData")
dfsim$alphaGO =c(paramA); dfsim$alphaLO = c(paramB); dfsim$betaO = paramC;
p1 = ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5)); p1
## R code for FOR PROBA LEARNING TASK OBIWAN
# last modified on April 2020 by David MUNOZ TORD
# PRELIMINARY STUFF ----------------------------------------
#if there is any bug please run this line below once ant then rerun the script
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))
#load packages
if(!require(pacman)) {
install.packages("pacman")
library(pacman)
}
pacman::p_load(tidyverse, plyr,dplyr,readr,rlist, ggpubr, NlcOptim,pracma, here, foreach, parallel, doSNOW, future, corrplot, RColorBrewer)
p1 = ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5)); p1
p2 = ggscatter(dfsim, x = "alphaLO", y = "alpha_neg", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Loss (Negative Learning Rate)', show.legend.text = FALSE ) + theme(plot.title = element_text(hjust = 0.5)); p2
p3 = ggscatter(dfsim, x = "betaO", y = "beta", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B2 (Choice Consistency)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5)); p3
p1 = ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5))+  scale_y_continuous( breaks = c(seq.int(0,1, by = 0.25)), limits = c(0,1)) +; p1
p1 = ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5))+  scale_y_continuous(breaks = c(seq.int(0,1, by = 0.25)), limits = c(0,1)) ; p1
test1 = summary(lm(alpha ~ alphaGO, data=dfsim)); test1$r.squared
test1 = summary(lm(alpha_pos ~ alphaGO, data=dfsim)); test1$r.squared
test2 = summary(lm(alpha_neg ~ alphaLO, data=dfsim)); test2$r.squared
test3 = summary(lm(beta ~ betaO, data=dfsim)); test3$r.squared
max(dfsim$beta)
max(dfsim$beta0)
max(dfsim$betaO)
dfsim = filter(dfsim, beta < 8)
max(dfsim$beta)
max(dfsim$betaO)
dfsim = filter(dfsim, betaO < 8)
max(dfsim$betaO)
p3 = ggscatter(dfsim, x = "betaO", y = "beta", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B2 (Choice Consistency)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5)); p3
test3 = summary(lm(beta ~ betaO, data=dfsim)); test3$r.squared
save(dfsim, file= "dfsim.RData")
p1 = ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5))+  scale_y_continuous(breaks = c(seq.int(0,1, by = 0.25)), limits = c(0,1)) ; p1
corrplot(cor(dfsim[c(1:3)]), type="upper", order="hclust",
col=brewer.pal(n=8, name="PuOr"))
ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5)
)
p2 = ggscatter(dfsim, x = "alphaLO", y = "alpha_neg", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Loss (Negative Learning Rate)', show.legend.text = FALSE ) + theme(plot.title = element_text(hjust = 0.5)); p2
p2 = ggscatter(dfsim, x = "alphaLO", y = "alpha_neg", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Loss (Negative Learning Rate)', show.legend.text = FALSE ) + theme(plot.title = element_text(hjust = 0.5))+  scale_y_continuous(breaks = c(seq.int(0,1, by = 0.25)), limits = c(0,1)); p2
p1 = ggscatter(dfsim, x = "alphaGO", y = "alpha_pos",
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Gain (Positive Learning Rate)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5))+  scale_y_continuous(breaks = c(seq.int(0,1, by = 0.25)), limits = c(0,1)) ; p1
p2 = ggscatter(dfsim, x = "alphaLO", y = "alpha_neg", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B1 Loss (Negative Learning Rate)', show.legend.text = FALSE ) + theme(plot.title = element_text(hjust = 0.5))+  scale_y_continuous(breaks = c(seq.int(0,1, by = 0.25)), limits = c(0,1)); p2
p3 = ggscatter(dfsim, x = "betaO", y = "beta", p.digits=2,p.accuracy=2,
add = "reg.line", conf.int = T,
add.params = list(color = "black", fill = "grey", size = 0.75), xlab = "Original", ylab = "Recovered", title = '\u03B2 (Choice Consistency)', show.legend.text = FALSE )  + theme(plot.title = element_text(hjust = 0.5)); p3
cairo_pdf(file.path(figures_path,'Figure_alphaG_full_sim.pdf'))
print(p1)
dev.off()
cairo_pdf(file.path(figures_path,'Figure_alphaL_full_sim.pdf'))
print(p2)
dev.off()
cairo_pdf(file.path(figures_path,'Figure_beta_full_sim.pdf'))
print(p3)
dev.off()
# SETUP ------------------------------------------------------------------
task = 'PBlearning'
# Set working directory #change here if the switchdrive is not on your home folder
analysis_path <- here::i_am()
analysis_path
## R code for FOR PROBA LEARNING TASK OBIWAN
# last modified on April 2020 by David MUNOZ TORD
# PRELIMINARY STUFF ----------------------------------------
#if there is any bug please run this line below once ant then rerun the script
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))
#load packages
if(!require(pacman)) {
install.packages("pacman")
library(pacman)
}
pacman::p_load(tidyverse, plyr,dplyr,readr,rlist, ggpubr, NlcOptim,pracma, here, foreach, parallel, doSNOW, future, corrplot, RColorBrewer)
# SETUP ------------------------------------------------------------------
task = 'PBlearning'
# Set working directory #change here if the switchdrive is not on your home folder
analysis_path <- here::i_am()
here::i_am()
analysis_path <- here::i_am(".git")
analysis_path <- here::here()
analysis_path
??here()
analysis_path <- here::i_am("Analysis/RECOVERY.R")
report::report_system()
##################################################################################################
# Created  by D.M.T. on AUGUST 2021
##################################################################################################
#                                      PRELIMINARY STUFF ----------------------------------------
#load libraries
if(!require(pacman)) {
install.packages("pacman")
install.packages("devtools")
library(pacman)
}
#get packages
pacman::p_load(tidyverse, dplyr, plyr, Rmisc, afex, BayesFactor, ggpubr)
# get tools
devtools::source_gist("383aa93ffa161665c0dca1103ef73d9d",
filename = "effect_CI.R")
devtools::source_gist("2a1bb0133ff568cbe28d",
filename = "geom_flat_violin.R")
# -------------------------------------------------------------------------
# *************************************** SETUP **************************************
# -------------------------------------------------------------------------
# Set path
analysis_path = getwd()
# Set working directory
figures_path  <- file.path(analysis_path, '../behavioral/figures')
setwd(analysis_path)
#datasets dictory
data_path <- file.path(analysis_path,'../behavioral/DATA')
# open datasets
HED  <- read.delim(file.path(data_path,'OBIWAN_HEDONIC.txt'), header = T, sep ='') #
info <- read.delim(file.path(data_path,'info_expe.txt'), header = T, sep ='') #
#subset only pretest
HED = subset(HED, session == 'second')
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123, 124 and 226 have imcomplete data
`%notin%` <- Negate(`%in%`)
HED = filter(HED, id %notin% c(242, 256, 114, 228, 123, 124, 226))
#merge with info
HED = merge(HED, info, by = "id")
# Check Demo
AGE = ddply(HED,.(), summarise,mean=mean(age),sd=sd(age), min = min(age), max = max(age)); AGE
GENDER = ddply(HED, .(id), summarise, gender=mean(as.numeric(gender)))  %>%
group_by(gender) %>%
tally() ; GENDER #1 = women
cov = ddply(HED, .(id),  summarize, age = mean(age, na.rm = TRUE), gender = mean(as.numeric(gender), na.rm = TRUE)) ; cov$age = scale(cov$age)
write.table(cov, (file.path(analysis_path, "../univariate/covariate.txt")), row.names = F, sep="\t")
# -------------------------------------- PLOTS -----------------------------------------------
# -------------------------------------- themes for plots --------------------------------------------------------
averaged_theme <- theme_bw(base_size = 32, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 32, face = "bold"),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
legend.position=c(.9,.9),
legend.title  = element_text(size = 12),
legend.text  = element_text(size = 10),
legend.key.size = unit(0.2, "cm"),
legend.key = element_rect(fill = "transparent", colour = "transparent"),
panel.grid.major.x = element_blank() ,
panel.grid.major.y = element_line(size=.2, color="lightgrey") ,
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 30),
axis.title.y = element_text(size =  30),
axis.line = element_line(size = 0.5),
panel.border = element_blank())
pal = viridis::inferno(n=5) # specialy conceived for colorblindness
HED.means <- aggregate(list(HED$perceived_liking, HED$perceived_intensity), by = list(HED$id, HED$condition), FUN='mean') # extract means
colnames(HED.means) <- c('id','condition','perceived_liking', 'perceived_intensity')
HED.means$int =  HED.means$perceived_intensity[HED.means$condition=="MilkShake"] - HED.means$perceived_intensity[HED.means$condition=="Empty"]; HED.means$int = scale(HED.means$int)
HED.means$lik =  HED.means$perceived_liking[HED.means$condition=="MilkShake"] - HED.means$perceived_liking[HED.means$condition=="Empty"]; HED.means$lik = scale(HED.means$lik)
HED.means$id = as.factor(HED.means$id); HED.means$condition = as.factor(HED.means$condition)
# AVERAGED EFFECT INTENSITY
dfH <- summarySEwithin(HED.means,
measurevar = "perceived_intensity",
withinvars = "condition",
idvar = "id")
dfH$cond <- ifelse(dfH$condition == "MilkShake", -0.25, 0.25)
HED.means$cond <- ifelse(HED.means$condition == "MilkShake", -0.25, 0.25)
set.seed(666)
HED.means <- HED.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
grouping = interaction(id, cond))
pp <- ggplot(HED.means, aes(x = cond, y = perceived_intensity,
fill = condition, color = condition)) +
geom_point(data = dfH, alpha = 0.5) +
geom_line(aes(x = condjit, group = id, y = perceived_intensity), alpha = .3, size = 0.5, color = 'gray') +
geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = condition, color = NA))+
geom_point(aes(x = condjit), alpha = .3,) +
geom_crossbar(data = dfH, aes(y = perceived_intensity, ymin=perceived_intensity-ci, ymax=perceived_intensity+ci,), width = 0.2 , alpha = 0.1)+
ylab('Perceived taste intesity') +
xlab('') +
scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
scale_x_continuous(labels=c("Milkshake", "Tasteless"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
scale_fill_manual(values=c("MilkShake"= pal[3], "Empty"=pal[1]), guide = 'none') +
scale_color_manual(values=c("MilkShake"=pal[3], "Empty"=pal[1]), guide = 'none') +
theme_bw()
ppp1 <- pp + averaged_theme + theme(plot.margin = margin(3,0.1,0.1,0.1, "cm"))
ppp1
# STATS -------------------------------------------------------------------
HED.means$condition <- relevel(HED.means$condition, "MilkShake") # Make MilkShake first
# intensity
t.test(perceived_intensity ~ condition, data = HED.means, paired = T)
cohen_d_ci(HED.means$perceived_intensity[HED.means$condition == "MilkShake"], HED.means$perceived_intensity[HED.means$condition == "Empty"], paired=T)
ttestBF(HED.means$perceived_intensity[HED.means$condition == "MilkShake"], HED.means$perceived_intensity[HED.means$condition == "Empty"])
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
help(Startup)
.libpaths()
system("source ~/.bashrc")
system(". ~/.bashrc")
cat("\nSuccessfully loaded .Rprofile at", date(), "\n")
system(source ~/.bashrc)
system("source ~/.bashrc")
Sys.setenv(BASH_ENV="~/.bashrc")
a = c(1,1,1)
b = c(1,1,1)
bind(a,b)
rbind(a,b)
cbind(a,b)
coerce(a,b)
norm(1.96)
rnorm(1.96)
dnorm(1.96)
a = c(1,1,1,1,5)
a(5)
a[length[a]]
a[length(a)]
library(DescTools)
attach(d.pizza)
a
b = a
cbind(a,b)
x  = as.Date(26.10.2021)
x  = as.Date("26-10-2021")
x
x[1]
as.month(x)
month(x)
attr(x)
months(x)
m = list(1,2,"c",4,5)
unlist(m)
f = cbind(a,b)
f
x = a
f= b
ft = cbind(x,f)
ft
merge(f,ft)
f
t= b
f = cbind(a,b)
merge(f,ft)
c(12L,34L,35L)
x = c(12L,34L,35L)
median(x)
typeof(median(x))
ls("V")
ls(char="V")
ls(pat="V")
fg = "V"
ls(pat="V")
ls(char<-"V")
V = 0
ls(pat="V")
ls(char="V")
c("c",3)
x = c("c",3)
typeof(x)
typeof(cbind(x,x)
)
str(cbind(x,x))
anovadata = o
anovadata = 0
ls(pat="V")
ls(pat="^V")
Varx = 0
ls(pat="^V")
arVx = 0
ls(pat="^V")
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
intern  <- automate_load_data(intern, read.csv, stringsAsFactors = T)
medic    <- automate_load_data(medic, read.csv, stringsAsFactors = T)
PAV      <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST     <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT      <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED      <- automate_load_data(HED, read.csv, stringsAsFactors = T)
HED_fMRI <- automate_load_data(HED_fMRI, read.csv, stringsAsFactors = T)
x = session_info();  opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE) # set F for all
# check_git()
# check_make()
# check_docker()
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly")) #remove scientific notation # remove warnings #set contrasts to sum !
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
emm_options(pbkrtest.limit = 5000) #increase repetitions limit
source('R/plots.R', echo=F)# plot specification
