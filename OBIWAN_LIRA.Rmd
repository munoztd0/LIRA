---
title: "OBIWAN PLACEBO VS. TREATMENT ANALYSIS REPORT"
author: "David Munoz Tord"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:  
    includes:
      in_header: header.html
    css: "style.css"
    code_folding: "hide"
    toc: true
    toc_float: false
    number_sections: false
  pdf_document:
    extra_dependencies: ["float"]
repro:
  data:
    HED: data/HEDONIC.csv
    INST: data/INST.csv
    PAV: data/PAV.csv
    PIT: data/PIT.csv
    intern: data/internal.csv
    medic: data/medic.csv
    HED_fMRI: data/HED_fmri.csv
    
  packages: [ aaronpeikert/repro@devel, crsh/papaja@devel, tinylabels, apaTables, MBESS, afex, ggplot2, ggpubr, Rmisc, emmeans, tidyr, BayesFactor, bayestestR, devtools, lspline, kableExtra, sjPlot, knitr, XML, rlist, janitor, optimx, ggthemes, dplyr, JWileymisc, corrplot, caret, intmed, stringr, cowplot, pander, psych, cmdstanr, brms, tidybayes, tibble, pbkrtest, scales]
  scripts: R/clean.R
  apt:
    - libgsl0-dev
---

### Setup {-}
<!-- # TO DO -->
  
```{r setup, results='hide', message=FALSE, warning=FALSE}

library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()

# load data
intern  <- automate_load_data(intern, read.csv, stringsAsFactors = T)
medic    <- automate_load_data(medic, read.csv, stringsAsFactors = T)
PAV      <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST     <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT      <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED      <- automate_load_data(HED, read.csv, stringsAsFactors = T)
HED_fMRI <- automate_load_data(HED_fMRI, read.csv, stringsAsFactors = T)




## we recommend running this is a fresh R session or restarting your current session
#install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#install_cmdstan()


# check_git(); check_make(); check_docker() #check if installed


sessio = session_info(); #opts_chunk$set(echo = F, message=F, warning=F) # set echo F for all


#May I suggest running `repro::automate()`? 

#This will create a `Dockerfile` & `Makefile` based on every RMarkdown in this folder and the special yamls in them. date: "`r format(Sys.time(), '%d %B, %Y')`" 

#add ENV DEBIAN_FRONTEND=noninteractive to DOCKERFILE
  
```

This file was automatically created via `the Repro package (version 0.1.0)` using  `r sessio$platform[1]`




```{r options, results='hide', message=FALSE, warning=FALSE}
niter = 5000; warm = 1000; chains = 4; cores = 4; nsim = 10000 # number of iterations (to change if you want to quick check and warmups (BUT chains and BF might be really unstable if you have less than 20'000 iter (4x5000) ) #or also parallel::detectCores()/2)
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = cores)  #remove scientific notation # remove warnings #set contrasts to sum ! #remove scientific notation # remove warnings #set contrasts to sum !
 #cl = parallel::detectCores()/2
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
#emm_options(pbkrtest.limit = 8000) #increase repetitions limit for frequentist stats

source('R/plots.R', echo=F)# plot specification
source('R/utils.R', echo=F)# useful functions

panderOptions('knitr.auto.asis', FALSE) #remove auto styling

labels <- c("-1" = "Pre", "1" = "Post")#for plots

# Look at R/clean.R (listed in the YAML) which does all the preprocessing for more info


# If you are unsure weather or not you have `git` `make` & `docker`.
# check_git()
# check_make()
# check_docker()
```




```{r clean, include=FALSE}
# this chunk runs R/clean.R (listed in the YAML) which does all the preprocessing
```

### Description
Stan uses Hamiltonian Monte Carlo (HMC) to explore the target distribution — the posterior defined by a Stan program + data — by simulating the evolution of a Hamiltonian system.


<!-- Parametric Bootstrap Test method to evaluate significance of fixed effects in mixed-effects models (using MLE fit, nsim = 5000) and Bayes Factor from mixed models (see Wagenmakers, 2007) -->

### Demographics
```{r demographics}
egltable(c("BMI", "AGE", "GENDER"), 
  g = "INTERVENTION", data = df, strict = FALSE) %>%
  kbl(caption ="Summary statistics", digits = 2) %>%
  kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')
```

### Biomedical data

#### Variable Selection  {-}


```{r var_plot, warning=FALSE, cache=TRUE, fig.align="center", out.width="90%", fig.cap="Box-plot of all biomedical predictors per intervention."}

# Boxplot of biomedical variables per group
ggplot(med)+
  geom_boxplot(aes(INTERVENTION, n))+
  facet_wrap(~feature, scales = "free")+
  labs(title = "")+
   theme_minimal()+
  theme(axis.title = element_text()) + 
  ylab("Biomedical predictor's value (scaled)") + 
  xlab('')

# Plot correlogram of numeric variables
#pairs(~., data = df[,8:19], main = "Scatterplot Matrix of variables")
#corrplot(cor(df[,8:19], use="pairwise.complete.obs"), type="lower")

```
\

Recursive Feature Eliminations 

```{r var_sel, cached=T,fig.align="center"}


#1) with Recursive Feature Eliminations (CARET)

sizes = 1:length(dfmed[c(-1)]); len = length(sizes)
seeds <- vector(mode = "list", length = len)
for(i in 1:(len-1)) seeds[[i]]<- sample.int(n=nsim, size = length(sizes)+1)
# for the last model
seeds[[len]]<-sample.int(nsim, 1)

RFEcontrol <- rfeControl(functions=rfFuncs, method="cv", number=10, seeds= seeds) # control options

rfeResults = rfe(x = dfmed[c(-1)], y = dfmed$intervention, sizes=sizes, rfeControl=RFEcontrol)
predictors(rfeResults)
plot(rfeResults, type=c("g", "o")) # look for the "elbow"

#if we agree that BMI, Body Weight and Waist Circumference actually measure the same thing, there only 4 other variables that are "useful" to separate the two groups :
#Reelin and GLP

```

#### Mediation analysis  {-}


```{r mediate}


#parallel:::setDefaultClusterOptions(setup_strategy = "sequential")

med_res <- intmed::mediate(y = "weightLoss", med = c("GLP_diff" ,  "reelin_diff"),  treat = "intervention", ymodel = "regression", mmodel = c("regression", "regression"), treat_lv = 1, control_lv = 0, incint = TRUE, inc_mmint = FALSE, conf.level = 0.95, data = df , sim = nsim, complete_analysis = TRUE, digits = 3,  summary_report=F) #c = c("age","gender"),

table <- list.clean(readHTMLTable("res.html"), fun = is.null, recursive = FALSE); table = table[3]$`NULL`[1:6,]

```


```{r mediate_res}


#pander(table)
colnames(table)[4] = "p"; table$p = as.numeric(table$p); table$p = ifelse(as.numeric(table$p) < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",table$p), "</span>"),  paste("<span>" ,sprintf("%.3f",table$p), "</span>")) # highlight p < 0.05
table$p = ifelse(table$p == '<span style=" font-weight: bold; " > 0.000 </span>', "<span style=\" font-weight: bold;    \" >\u003C 0.001</span>", table$p)


table[-c(3:4),] %>%
  kbl(caption ="Mediation Analysis: DV = Weight loss, IV = Intervention", escape=F) %>%
  kable_styling(latex_options = "HOLD_position", position = "center", full_width = F)

#just for plot purpose (because not the same exact analysis)
medi =  psych::mediate(weightLoss ~ intervention + (GLP_diff) + (reelin_diff), data = df, n.iter = nsim, plot=F); psych::mediate.diagram(medi, show.c=FALSE)
```

### Weight Loss

```{r weigth_loss, results = "hide"}

# Model
mf = formula(weightLoss ~ intervention + gender + age + GLP_diff + reelin_diff  + (1|id))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
# STAN is a probabilistic programming language that allows you to get full Bayesian statistical inference with MCMC sampling.


bmod_full = brm(mf, data=df, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4), control = list(adapt_delta = 0.99)) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF 3)larger step size  




#problem here!!

#lmer to compare
fmod_full = lm(update(mf, ~.- (1|id)) , data = df)
```

```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full, pars =c("b_.*en", "b_.*ge"), type ="areas")

trace = mcmc_plot(object = bmod_full, pars =c("b_.*en", "b_.*ge"), type ="trace")

#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "intervention", binwidth = 0.1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 100) # check response fit

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <- residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagWEIGHT <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagWEIGHT, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```





```{r WEIGHT_tab, results='hide'}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_sigma"))



# -------------------------------------- FREQUENTIST STATS: AOV -----------------------------------------------

# formula = 'weightLoss ~ intervention + gender + age  + Error(id)'
# 
# 
# mdl.weight = aov_car(as.formula(formula), data = df, factorize = FALSE,  anova_table = list(correction = "GG", es = "pes"),type = "II")
# res = nice(mdl.weight, MSE = F); ref_grid(mdl.weight); res
# 
# PES.weight = pes_ci(as.formula(formula), data = df, conf.level = .90, factorize = FALSE, anova.type = "II", epsilon="none") ; 
# mdl.weight.emms = emmeans(mdl.weight, pairwise ~ intervention)


# res$p.value = as.numeric(res$p.value)
# res$p.value = ifelse(res$p.value < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",res$p.value), "</span>"),  paste("<span>" ,sprintf("%.3f",res$p.value), "</span>"))
# 
# res$F = unlist(str_split(gsub("[^0-9.,-]", "", res$F), ","));res$pes = unlist(str_split(gsub("[^0-9.,-]", "", res$pes), ","));
# res$`90% CI` = paste(sprintf("%.3f",PES.weight[,2]), "-", sprintf("%.3f",PES.weight[,3]))
# 
# res$p.value[1]= "<span style=\" font-weight: bold;    \" >\u003C 0.001</span>"
# colnames(res)[3:5] = c( paste("F(", res$df[1], ")", sep=""),"&eta;<sub>p</sub><sup>2</sup>", "p")
# res[c(1,4,6,3,5)]  %>% kbl(digits = 2, escape = F) %>%
#   kable_styling(latex_options = "striped", position = "center", full_width = F) 

# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Weight Loss (\u0394 BMI)", file = "tmp/temp1.html", transform = NULL,  rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r WEIGHT_res}

print(paste("Bayesian linear mixed model (estimated using MCMC sampling with " ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict weightLoss with intervention, gender, age, GLP_diff and reelin_diff (formula: weightLoss ~ intervention + gender + age + GLP_diff + reelin_diff). The model included id as random effect (formula: ~1 | id). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 2.50) distributions"))
            

full_tab

report[4]

tables <- list.clean(readHTMLTable("tmp/temp1.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble();


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+4),1:2]);
tmp[,4][1] = "R2"; tmp[,4][2] = gsub(".*/","",tmp[,4][2]); colnames(tmp) =  tmp[1,]
pander:: pander(tmp[2,])


```

#### Plot Weight Loss {-}


```{r Weight_Loss, warning=FALSE, cache=TRUE, fig.align="center", fig.cap="Weight Loss by intervention."}


dfdraws = bmod_full %>%
    spread_draws(`b_intervention` )


HDI_weight = plotHDI( dfdraws$`b_intervention` , credMass = .90, binSize = 100, Title = "") + theme_bw() + html_theme  


dfdraws2 =  bmod_full %>%
     emmeans(~ intervention) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>%
    ggplot(aes(x = as.factor(intervention) , y = .value,  fill = as.factor(intervention))) +
    geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    labs(x = "",y = "Weight Loss (\u0394 BMI)", title = "") + 
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[6]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[6]), guide="none") +
    scale_x_discrete(labels=c("Placebo", "Liraglutide")) +
  #scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(400,550, by = 50)), limits = c(380,575)) +
    theme_bw()

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figureWL <- ggarrange(plt_bayes_html, HDI_weight,
                    labels = c("A", "B"),
                    ncol = 2)
#figureWL




dfR <- summarySE(df, measurevar = "weightLoss",
                 groupvars = "INTERVENTION")

dfR$cond <- ifelse(dfR$INTERVENTION == "Liraglutide", -0.25, 0.25)
df$cond <- ifelse(df$INTERVENTION == "Liraglutide", -0.25, 0.25)
df <- df %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
                    grouping = interaction(id, cond))

pp <- ggplot(df, aes(x = cond, y = weightLoss, 
                     fill = INTERVENTION, color = INTERVENTION)) +
  geom_hline(yintercept=0, linetype="dashed", size=0.4, alpha=0.8) +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = INTERVENTION, color = NA))+
  geom_point(aes(x = condjit), alpha = .3,) +
  geom_crossbar(data = dfR, aes(y = weightLoss, ymin=weightLoss-se, ymax=weightLoss+se), width = 0.2 , alpha = 0.1)+
  ylab('Weight loss (\u0394 BMI)')+xlab('')+
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(-2.5,7.5, by = 2.5)), limits = c(-3,8)) +
  scale_x_continuous(labels=c("Liraglutide", "Placebo"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("Liraglutide"= pal[6], "Placebo"=  pal[1]), guide = 'none') +
  scale_color_manual(values=c("Liraglutide"= pal[6], "Placebo"=  pal[1]), guide = 'none') +
  theme_bw() 

plt = pp + averaged_theme 
pp + html_theme 
```
\
\


```{r weight_saveFIG, results = "hide"}

cairo_pdf('figures/Figure_WL_Lira.pdf')
print(plt)
dev.off()

cairo_pdf('figures/Figure_WL_Lira_Bayes.pdf')
print(figureWL)
dev.off()
```

### Pavlvovian Conditioning Task 

#### Latency {-}
Latency = time to detect the target (ms) & condition = CS+ or CS-


```{r PAV_RT, cache=F, results = "hide"}

# Model
mf = formula(RT ~ condition*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (condition*session|id) + (1|trialxcondition))


# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
# STAN is a probabilistic programming language that allows you to get full Bayesian statistical inference with MCMC sampling.
bmod_full = brm(mf, data=PAV, family = exgaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4), max_treedepth=15) # a lot to unwind here..  1) Generic informative prior around 0 for fixed effects and weak prior for the intercept 2) we need to sample priors and save parameters for computing BF  3) account for the skewness of reaction times #family = "exgaussian"


#lmer to compare
fmod_full = lmer(mf , data = PAV, REML=F, control = control )
```


```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full, pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="areas")

trace = mcmc_plot(object = bmod_full, pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "intervention", binwidth = 1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit -> accounting for skewness, nice!

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagRT <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagRT, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```



```{r PAV_tab, cache=F, results='hide'}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_beta", "prior_sigma"))



# -------------------------------------- FREQUENTIST STATS: LRT -----------------------------------------------
#measurevar = "RT"
# formula = "condition*intervention*session"
# COVA = "+ condition*age + gender + BMI_V1  + thirsty  + hungry +"
# random = " (condition*session|id) + (1|trialxcondition)"
# 
# #method LRT 
# model = mixed(as.formula(paste(measurevar, paste (formula, COVA, random), sep="~")), data = PAV, method = "LRT", control = control, REML = FALSE); model
# 
# table = nice(model);  ref_grid(model)  #triple check everything is centered at 0
# 
# 
# mod =  lmer(as.formula(paste(measurevar, paste (formula, COVA, random), sep="~")), data = PAV, control = control)

# tab_model(mod, show.p = T,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 2, dv.labels = "Latency", emph.p = TRUE, file = "tmp/temp1.html")

# tables <- list.clean(readHTMLTable("tmp/temp1.html"), fun = is.null, recursive = FALSE)
# tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
# 
# tables2 <- as.matrix(tables2) %>% as_tibble()
# tables2[is.na(tables2)] <- ""
# tables3 = tables2[1:length(table$Effect),1:4] 
# tables3[5] = str_split(gsub("[^0-9.,-]", "", table[3]), ",")[[1]]; tables3[6] = as.numeric(str_split(gsub("[^0-9.,-]", "", table[4]), ",")[[1]]); 
# tables3$...6 = ifelse(tables3$...6 < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",tables3$...6), "</span>"),  paste("<span>" ,sprintf("%.3f",tables3$...6), "</span>"))
# colnames(tables3)[5] = "\u03C7\u00B2"; colnames(tables3)[6] = "p"
# tables3$p[1]= "<span style=\" font-weight: bold;    \" >\u003C 0.001</span>"
# tables3 %>%   
#   kbl(caption ="Latency (ms)",escape = F) %>%
#   kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%  row_spec(0,bold=T,align='c')
# tmp = tables2[(length(table$Effect)+1):(length(table$Effect)+5),1:2]
# names(tmp) <- NULL
# tmp1 <- data.frame(t(tmp[-1]))
# colnames(tmp1) <- tmp[[1]]
# tmp1 %>% kbl(digits = 2) %>%
#   kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) 


# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Latency (ms)", file = "tmp/temp2.html", transform = NULL,  rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r PAV_res}

print(paste("Bayesian general linear mixed model (exgaussian family with a identity link) (estimated using MCMC sampling with " ,chains ,"chains of", niter, "iterations and a warmup of", warm, ") to predict Latency with condition, intervention, session, age, gender, BMI_V1, hungry, GLP_diff and reelin_diff (formula: RT ~ condition * intervention * session + age + gender + BMI_V1 + hungry + GLP_diff + reelin_diff). The model included condition, session, id and trialxcondition as random effects (formula: list(~condition * session | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 130.20) distributions"))
            

full_tab

report[4]

tables <- list.clean(readHTMLTable("tmp/temp2.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()

# check for bad ICC?
tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2]); colnames(tmp) =  tmp[1,]
pander:: pander(tmp[2,])


```
\

#### Plot Latency {-}
```{r PAV_RT_plot, message=FALSE, warning=FALSE, cache=F, fig.align="center", fig.cap="A) Posterior distribution by Pavlovian cue. B) Highest density interval (90% HDI) of the posterior distribution difference for the latency to respond between CS+ and CS-"}


dfdraws = bmod_full %>%
    spread_draws(`b_condition` )


HDI_RT = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw() + html_theme  


dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>%
    ggplot(aes(x = as.factor(condition) , y = .value,  fill = as.factor(condition))) +
    #geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    labs(x = "", y = "Latency (ms)", title = "") + 
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_x_discrete(labels=c("CS-", "CS+")) +
  #scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(400,550, by = 50)), limits = c(380,575)) +
    theme_bw()

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figureRT <- ggarrange(plt_bayes_html, HDI_RT,
                    labels = c("A", "B"),
                    ncol = 2)
#figureRT



# RT


dfR <- summarySEwithin(PAV.means,
                       measurevar = "RT",
                       withinvars = c("condition","session"), 
                       idvar = "id")

dfR$cond <- ifelse(dfR$condition == "1", -0.25, 0.25)
PAV.means$cond <- ifelse(PAV.means$condition == "1", -0.25, 0.25)
PAV.means <- PAV.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
                                  grouping = interaction(id, cond))

pp <- ggplot(PAV.means, aes(x = cond, y = RT, 
                            fill = as.factor(condition), color = as.factor(condition))) +
  geom_line(aes(x = condjit, group = id, y = RT), alpha = .3, size = 0.5, color = 'gray') +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
  geom_point(aes(x = condjit, shape = as.factor(intervention)), alpha = .3,) +
  geom_crossbar(data = dfR, aes(y = RT, ymin=RT-se, ymax=RT+se), width = 0.2 , alpha = 0.1)+
  ylab('Latency (ms)')+
  xlab('Conditioned stimulus')+
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(200,1000, by = 200)), limits = c(150,1050)) +
  scale_x_continuous(labels=c("CS+", "CS-"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_shape_manual(name="Intervention", labels=c("Placebo", "Liraglutide"), values = c(1, 2)) +
  theme_bw() + facet_wrap(~session, labeller=labeller(session = labels))

plt = pp + averaged_theme  + theme(legend.position=c(.96,.94), axis.text.x = element_text(size = 14))
pp + html_theme  + theme(legend.position=c(.96,.94), axis.text.x = element_text(size = 14))
```


```{r PAV_RT_saveFIG, results = "hide"}

cairo_pdf('figures/Figure_PavlovianRT_Lira.pdf')
print(plt)
dev.off

cairo_pdf('figures/Figure_PavlovianRT_Lira_Bayes.pdf')
print(figureRT)
dev.off()
```

#### Perceived liking (Pavlovian Cue) {-}

Ratings = how pleasant is the clue (0-100, no repetitions)   &   condition = CS+ or CS-


```{r PAV_Lik, message=FALSE, cache=F, results = "hide"}

# Model
mf = formula(liking ~ condition*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (condition*session|id))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------


bmod_full = brm(mf, data=PAV.means, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4), control = list(adapt_delta = 0.99))  # a lot to unwind here..  1) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 2) we need to sample priors and save parameters for computing BF  3)larger step size  



#lmer to compare
fmod_full <- lmer(update(mf, ~ .-(condition*session|id)+(condition+session|id)) , data=PAV.means) #cannot maximize random structure here
```

```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full, pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="areas")

trace = mcmc_plot(object = bmod_full, pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "intervention", binwidth = 1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagLik <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagLik, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```




```{r PAV_tab_lik,  cache=F, results='hide'}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_beta", "prior_sigma"))



# -------------------------------------- FREQUENTIST STATS: -----------------------------------------------

# measurevar = "liking"
# formula = "condition*intervention*session"
# COVA = "+ age + gender + BMI_V1 + "
# random = "Error(id/session*condition)"
#  
# mdl.lik = aov_car(as.formula(paste(measurevar, paste (formula, COVA, random), sep="~")), data= PAV.means, factorize = F, anova_table = list(correction = "GG", es = "pes"))
# res = nice(mdl.lik, MSE=F);  res = res[c(10,1:6,11,15,16),] #clean up unesuful an reorder
# ref_grid(mdl.lik)  #triple check everything is centered at 0
# 
# #calculate Partial eta-squared and its 90 % CI for each effect
# PES.lik = pes_ci(as.formula(paste(measurevar, paste (formula, COVA, random), sep="~")), data = PAV.means, conf.level = .90, factorize = FALSE, anova.type = "II", epsilon="none") ;  PES.lik = PES.lik[c(10,1:6,11,15,16),]
# mdl.lik.emms = emmeans(mdl.lik, pairwise ~ condition)
# 
# res$p.value = as.numeric(res$p.value)
# res$p.value = ifelse(res$p.value < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",res$p.value), "</span>"),  paste("<span>" ,sprintf("%.3f",res$p.value), "</span>"))
# 
# res$F = unlist(str_split(gsub("[^0-9.,-]", "", res$F), ","));res$pes = unlist(str_split(gsub("[^0-9.,-]", "", res$pes), ","));
# res$`90% CI` = paste(sprintf("%.3f",PES.lik[,2]), "-", sprintf("%.3f",PES.lik[,3]))
# 
# res$p.value[1]= "<span style=\" font-weight: bold;    \" >\u003C 0.001</span>"
# res$pes[c(5,7,8)]= c("\u003C 0.001")
# colnames(res)[3:5] = c( paste("F(", res$df[1], ")", sep=""),"&eta;<sub>p</sub><sup>2</sup>", "p")
# res[c(1,4,6,3,5)]  %>% kbl(digits = 2, escape = F,row.names = F)  %>%
#   kable_styling(latex_options = "striped", position = "center", full_width = F) 

# -------------------------------------- Regression table summary --------------------------------------

tab_model(fmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Perceived liking", file = "tmp/temp3.html", rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r PAV_res_lik}

print(paste("Bayesian linear mixed model (estimated using MCMC sampling with" ,chains ," chains of", niter, " iterations and a warmup of", warm, ")  to predict liking with condition, intervention, session, age, gender, BMI_V1, hungry, GLP_diff and reelin_diff (formula: liking ~ condition * intervention * session + age + gender + BMI_V1 + hungry + GLP_diff + reelin_diff). The model included condition, session and id as random effects (formula: ~condition * session | id). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 15.10) distributions"))

full_tab

report[c(4,10)]
tables <- list.clean(readHTMLTable("tmp/temp3.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+4),1:2]);
tmp[,4][1] = "R2"; tmp[,4][2] = gsub(".*/","",tmp[,4][2])
pander::pander(tmp)
```
\
\


#### Plot Perceived liking (Pavlovian Cue) {-}
```{r PAV_lik_plot, message=FALSE, warning=FALSE, cache=F, fig.align="center", fig.cap="A) Posterior distribution by Pavlovian cue. B) Highest density interval (90% HDI) of the posterior distribution difference for the latency to respond between CS+ and CS-"}

dfdraws = bmod_full %>%
    spread_draws(`b_condition`,`b_hungry` )


HDI_cond_PAV = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw()

HDI_hunger_PAV = plotHDI( dfdraws$`b_hungry` , credMass = .90, binSize = 100, Title = "") + theme_bw() # also mcmc_plot(object = bmod_full, pars =c("b_hungry"), type ="areas", prob = 0.9)



dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>%
    ggplot(aes(x = as.factor(condition) , y = .value,  fill = as.factor(condition))) +
    geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    #geom_point(position = "jitter") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    ylab('Perceived liking')+
    xlab('')+
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[2]), guide="none") +
    scale_x_discrete(labels=c("CS-", "CS+")) +
     scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 25)), limits = c(-0.05,100.5)) +
    theme_bw()# + facet_wrap(~group, labeller=labeller(group =labels))

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 

figurePAV <- ggarrange(plt_bayes_html, HDI_cond_PAV,
                    labels = c("A", "B"),
                    ncol = 2)
#figurePAV


# Liking

dfL <- summarySEwithin(PAV.means,
                       measurevar = "liking",
                       withinvars = c("condition", "session"), 
                       idvar = "id")

dfL$cond <- ifelse(dfL$condition == "1", -0.25, 0.25)


pp <- ggplot(PAV.means, aes(x = cond, y = liking, 
                            fill = as.factor(condition), color = as.factor(condition))) +
  geom_hline(yintercept=50, linetype="dashed", size=0.4, alpha=0.8) +
  geom_line(aes(x = condjit, group = id, y = liking), alpha = .3, size = 0.5, color = 'gray' ) +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill =  as.factor(condition), color = NA)) +
  geom_point(aes(x = condjit, shape =  as.factor(intervention)), alpha = .3) +
  geom_crossbar(data = dfL, aes(y = liking, ymin=liking-se, ymax=liking+se), width = 0.2 , alpha = 0.1)+
  ylab('Liking Ratings')+
  xlab('Conditioned stimulus')+
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 25)), limits = c(-0.05,100.5)) +
  scale_x_continuous(labels=c("CS+", "CS-"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
  scale_shape_manual(name="Intervention", labels=c("Placebo", "Liraglutide"), values = c(1, 2)) +
  theme_bw()+ facet_wrap(~session, labeller=labeller(session = labels))


plt = pp + averaged_theme  + theme(legend.position=c(.96,.94), axis.text.x = element_text(size = 14))
pp + html_theme  + theme(legend.position=c(.96,.94), axis.text.x = element_text(size = 14))
```
\
\


```{r PAV_lik_saveFIG, results = "hide"}

cairo_pdf('figures/Figure_PavlovianLiking_Lira.pdf')
print(plt)
dev.off()

cairo_pdf('figures/Figure_PavlovianLiking_Lira_Bayes.pdf')
print(figurePAV)
dev.off()
```

### Instrumental Conditioning Task
grips = number of times participant exceeded the force threshold to acquire the reward (Milkshake)
\



```{r INST, cache=F, results = "hide"}

# Model
mf1 = formula(grips ~ trialZ*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (session|id) + (1|trialZ)) # LINEAR FIT  
mf2 = formula(grips ~  lspline(trialZ,-1.08327290)*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (session|id) + (1|trialZ)) # PIECEWISE REGRESSION WITH SPLINE AT 5 #(-1.08327290 is 5 after scaling)


# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------
linmod = brm(mf1, data=INST, family = gaussian, prior = c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = "")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstanr', threads = threading(4))  # a lot to unwind here..  1) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 2) we need to sample priors and save parameters for computing BF  

splinemod = update(linmod, formula. = mf2)

linmod$loo = loo(linmod); splinemod$loo = loo(splinemod)
comp = loo::loo_compare(linmod$loo, splinemod$loo) 

bmod_full = splinemod #winner model

#lmer to compare
fmod_full = lmer(mf2 , data = INST, REML=F, control = control )
```

Model Comparison between linear and piecewise with spline regression\
Best fit => Piecewise Regression with spline: smaller ELPD (expected log pointwise predictive density estimated via leave-one-out cross-validation) is better\
```{r}
comp = tibble::rownames_to_column(as_tibble(comp, rownames = NA)); colnames(comp)[1] = "model"
pander(comp[c(1:3,8:9)]) # so the splinemod was preferred as the other model had smaller ELPD. Thus, spline improved out-of-sample predictions. can also see: compare_ic(linmod, splinemod) but its deprecated
```


```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling

param = mcmc_plot(object = bmod_full, pars =c("b_.*al"), type ="areas")
param2 = mcmc_plot(object = bmod_full, pars =c("b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="areas")
param = param + scale_y_discrete(labels=c("trial<5", "trial>5", "trial<5:intervention", "trial>5:intervention","trial<5:session", "trial>5:session", "trial<5:intervention:session", "trial>5:intervention:session"))

trace = mcmc_plot(object = bmod_full, pars =c("b_.*al"), type ="trace")
trace2 = mcmc_plot(object = bmod_full, pars =c("b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="trace")

#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", group = "intervention", binwidth = 0.01, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagINST <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagINST, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
```



```{r INST_tab, cache=F, results='hide'}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))

full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "prior_beta", "prior_sigma"))

x = attributes(full_tab); x$clean_parameters[c(2:3,12:15,17:18),5] = c("trial<5",       "trial>5", "trial<5:intervention", "trial>5:intervention","trial<5:session", "trial>5:session", "trial<5:intervention:session", "trial>5:intervention:session"); attributes(full_tab) = x


# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------

# fmod_spline =  update(fmod_full, ~ .-lspline(trial,-1.08327290)) #evaluate trial spline
# 
# # p-value from bootstrap distribution
# LRT_spline = PBmodcomp(fmod_full, fmod_spline, nsim = 500, seed = 123, cl=cores)


# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F, show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Number of Grips", file = "tmp/temp4.html", transform = NULL,  rm.terms = "beta")

report = capture.output(sexit(bmod_full, ci=.9, large = 0.69))

```

```{r INST_res}

print(paste("Bayesian linear mixed model (estimated using MCMC sampling with" ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict grips with trial, intervention, session, age, gender, BMI_V1, hungry, GLP_diff and reelin_diff (formula: grips ~ lspline(trial, 5) + intervention + session + age + gender + BMI_V1 + hungry + GLP_diff + reelin_diff + lspline(trial, 5):intervention + lspline(trial, 5):session + intervention:session + lspline(trial, 5):intervention:session). The model included session, id and trial as random effects (formula: list(~session | id, ~1 | trial)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 8.90) distributions"))

full_tab

x = report[c(4:5,16)]; x = gsub('b_lsplinetrialZM1.08327291', 'b_trial<5', x); x = gsub('b_lsplinetrialZM1.08327292', 'b_trial>5', x); x

tables <- list.clean(readHTMLTable("tmp/temp4.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t( tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)


```
\
\


#### Plot {-}


```{r INST_plot, results='hide', warning=FALSE, message=FALSE, cache=F, fig.cap="Number of grips over trials by session."}


int_conditions <- list(
  session = setNames(c(-1, 1), c("pre", "post"))
)
plt = conditional_effects(bmod_full, effects = "trialZ:session",
                    int_conditions = int_conditions) #easier to extract spline with brms

dfTRIAL = as_tibble(plt$trial); dfTRIAL$grips = dfTRIAL$estimate__ ; dfTRIAL$trial = rescale(dfTRIAL$trialZ, to = c(1,24))


#by groups

dfTRIALg <- summarySEwithin(INST.means,
                            measurevar = "grips",
                            withinvars = c("trial", "session"),
                            betweenvars = "intervention",
                            idvar = "id")

dfTRIALg$trial       <- as.numeric(as.character(dfTRIALg$trial))

pp <-  ggplot(dfTRIAL, aes(x = trial, y = grips)) +
  geom_point(data = dfTRIALg, aes(shape = intervention), alpha = 0.3, color = 'black') +
  geom_line(data = dfTRIAL, size =1, color = pal[4]) +
  geom_ribbon(aes(ymin=grips-se__, ymax=grips+se__), fill = pal[4], alpha = 0.3, )+
  ylab('Number of Grips')+
  xlab('Trial') +
  scale_y_continuous(expand = c(0, 0),  limits = c(9.5,16.05),  breaks=c(seq.int(9,16, by = 1))) +
  #scale_x_continuous(expand = c(0, 0),  limits = c(-2,2),  breaks=c(seq.int(-2,2, by = 0.5))) +
  scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
  theme_bw() +
  facet_wrap(~session, labeller=labeller(session = labels))



pp + html_theme + theme(legend.position=c(.9,.88),axis.text.x = element_text(size = 14))

plt = pp + averaged_theme + theme(legend.position=c(.9,.88),axis.text.x = element_text(size = 14))

```
\
\


```{r INST_saveFIG, results = "hide"}

cairo_pdf('figures/Figure_INST_trial_LIRA.pdf')
print(plt)
dev.off()
```


### Pavlvovian-Instrumental Transfer (PIT) Task 
Mobilized effort = Area under the curve of the force exerted exceeding the delivery threshold during Pavlovian cue presentation


```{r PIT, results='hide', message=FALSE, warning=FALSE}

mf = formula(AUC ~ condition*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + (condition*session|id) + (1|trialxcondition))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------


bmod_full = brm(bf(mf, hu ~ 1), family = hurdle_gaussian, stanvars = stanvars, data=PIT.clean, prior =  c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = ""), prior(logistic(0, 0.5), class = "Intercept", dpar = "hu")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstan', threads = threading(4), control = list(adapt_delta = 0.99)) # a lot to unwind here.. 1) custom gaussian hurdle cause zero-inflated continous data more details here: https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html 2) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 3) we need to sample priors and save parameters for computing BF 4)increased step size

#lmer to compare
fmod_full = lmer(mf , data = PIT.clean, REML=F, control = control)

```


```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling
param = mcmc_plot(object = bmod_full,  pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="areas") 

trace = mcmc_plot(object = bmod_full,  pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", stat = "median", group = "intervention", binwidth = 1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagPIT <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagPIT, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
# check response fit -> capture better the bimodal distrib
# residual ... could be better but at least it's MUCH better than simple gaussian see lmx[1] ... this is just catastrophic..
```




```{r PIT_res,  cache=F, results='hide'}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))



full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "b_hu_Intercept", "prior_sigma"))

# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------

 fmod_cond = update(fmod_full,  ~ .-condition) #evaluate condition

# # p-value from bootstrap distribution
 LRT_cond = PBmodcomp(fmod_full, fmod_cond, nsim = 500, seed = 123, cl=cores)

# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Mobilized effort (a.u.)", file = "tmp/temp5.html", transform = NULL,  rm.terms = "hu_Intercept")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r PIT_tab}
print(paste("Bayesian general linear mixed model (hurdle gaussian family with a identity link) (estimated using MCMC sampling with" ,chains ," chains of", niter, " iterations and a warmup of", warm, ") to predict Mobilized Effort (AUC) with condition, intervention, session, age, gender, BMI_V1, hungry, GLP_diff and reelin_diff (formula: AUC ~ condition * intervention * session + age + gender + BMI_V1 + hungry + GLP_diff + reelin_diff). The model included condition, session, id and trialxcondition as random effects (formula: list(~condition * session | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00), and student_t (location = 0.00, scale = 130.20) distributions"))
            

full_tab

report[5]


tables <- list.clean(readHTMLTable("tmp/temp5.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble(); 


tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)

```

#### Plot {-}


```{r PIT_plot, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="A) Posterior distribution by group. B) Highest density interval (90% HDI) for the interaction condition by session"}

# plot HDI
dfdraws = bmod_full %>%
    spread_draws(`b_condition` )

HDI_PIT = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw()


#plot estimated means from posterior distribution from the model draws


dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 

# CSp = subset(dfdraws2, condition ==1); CSm = subset(dfdraws2, condition ==-1); diff= CSp; diff$.value = CSp$.value - CSm$.value


pp = dfdraws2 %>% #diff
    ggplot(aes(x = as.factor(condition) , y = .value,  fill = as.factor(condition))) +
    #geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    #geom_point(position = "jitter") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    ylab('Mobilized effort')+
    xlab('')+
    scale_fill_manual(values=c("1" = pal[6],"-1"=pal[1]), guide="none") +
    scale_color_manual( values=c("1" = pal[6],"-1"=pal[1]), guide="none") +
    scale_x_discrete(labels=c("CS-", "CS+")) +
    theme_bw()

plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figurePIT <- ggarrange(plt_bayes_html, HDI_PIT,
                    labels = c("A", "B"),
                    ncol = 2)
#figurePIT


#### Plot PIT

dfL <- summarySEwithin(PIT.means,
                       measurevar = "AUC",
                       withinvars = c("condition","session"), 
                       idvar = "id")

dfL$cond <- ifelse(dfL$condition == "1", -0.25, 0.25)
PIT.means$cond <- ifelse(PIT.means$condition == "1", -0.25, 0.25)
PIT.means <- PIT.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),grouping = interaction(id, cond))


# AUC
pp <- ggplot(PIT.means, aes(x = cond, y = AUC,
                            fill = as.factor(condition), color = as.factor(condition))) +
  geom_line(aes(x = condjit, group = id, y = AUC), alpha = .3, size = 0.5, color = 'gray' ) +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA)) +
  geom_point(aes(x = condjit, shape = as.factor(intervention)), alpha = .3) +
  geom_crossbar(data = dfL, aes(y = AUC, ymin=AUC-se, ymax=AUC+se), width = 0.2 , alpha = 0.1)+
  ylab('Mobilized effort (a.u.)')+
  xlab('Condition')+
  #scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,30, by = 5)), limits = c(-0.05,30.5)) +
  scale_x_continuous(labels=c("CS+", "CS-"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("1"= pal[6], "-1"=  pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"= pal[6], "-1"=  pal[1]), guide = 'none') +
  scale_shape_manual(name="Intervention", labels=c("Placebo", "Liraglutide"), values = c(1, 2)) +
  theme_bw()+ facet_wrap(~session, labeller=labeller(session = labels))



pp + html_theme +theme(legend.position=c(.94,.94))
plt = pp + averaged_theme +theme(legend.position=c(.94,.94))
```

```{r PIT_time, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="Mobilized effort for each condition and group over trials."}


# PLOT OVERTIME


pp <- ggplot(PIT.p, aes(x = as.numeric(trial), y = AUC,
                        color = condition,
                        fill  = condition))+
    geom_point(data = PIT.group, aes(shape = intervention, color = condition), alpha = 0.3) +
  geom_line(alpha = .5, size = 1, show.legend = F) +
  geom_ribbon(aes(ymax = AUC + se, ymin = AUC - se),  alpha=0.4) +
  geom_point() +
  ylab('Mobilized effort (a.u.)')+
  xlab('Trial')+
  scale_color_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
                     values = c("1"= pal[6], '-1'= pal[1])) +
  scale_fill_manual(labels = c('-1'= 'CS-', "1" = 'CS+'), name="",
                    values = c("1"= pal[6], '-1'= pal[1])) +
  scale_y_continuous(expand = c(0, 0),  limits = c(50,200),  breaks=c(seq.int(50,200, by = 50))) +
  #scale_x_continuous(expand = c(0, 0),  limits = c(0,15),  breaks=c(seq.int(1,15, by = 2))) +
    scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
  theme_bw() +
  facet_wrap(~session, labeller=labeller(session =labels))


pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.3, "cm"))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), legend.key.size = unit(0.8, "cm"), axis.text.x = element_text(size = 16))



# bmod_time = update(bmod_full,  ~ .+as.factor(trialxcondition)) #evaluate interaction
# 
# df =  bmod_time %>%
#      emmeans(~ condition:session:trialxcondition) 
# 
# 
# 
# bayes_plt = as_tibble(df) %>%
#     ggplot(aes(x = trialxcondition, y = emmean,  fill =as.factor(condition))) +
#     #geom_point(position = "jitter") +
#     geom_smooth(method=loess, se = T,inherit.aes = T) + 
#     #stat_slab(.width = c(0.50, 0.95),position="dodge", alpha=0.5) +
#     #stat_pointinterval(.width = c(0.50, 0.95),position="dodge") +
#     ylab('Mobilized effort (a.u.) \n Baseline corrected')+
#     xlab('')+
#     scale_fill_manual(values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     scale_color_manual( values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     #scale_x_discrete(labels=c("CS+", "CS-")) +
#     theme_bw() + facet_wrap(~session, labeller=labeller(session =labels))

```

\

```{r PIT_save, results = "hide"}

cairo_pdf('figures/Figure_PIT_Lira.pdf')
print(plt)
dev.off()

cairo_pdf('figures/Figure_PIT_Lira_Bayes.pdf')
print(figurePIT)
dev.off()
```


# Hedonic Reactivity Test 
Perceived liking = how pleasant is the liquid solution rated (0-100, with repetitions)   &   condition = Milshake or Tasteless   &   intensity = difference on how intense the liquid solution were rated (mean(Milshake) - mean(Tasteless)) &   familiarity = difference on how familiar the liquid solution were rated (mean(Milshake) - mean(Tasteless))


```{r HED, cache=F, results = "hide"}

mf = formula(perceived_liking ~ condition*intervention*session + age + gender + BMI_V1  + hungry + GLP_diff + reelin_diff + int + fam + (condition*session|id) + (1|trialxcondition))

# -------------------------------------- Bayesian Regression Models using Stan -------------------------------------


bmod_full = brm(bf(mf, hu ~ 1), family = hurdle_gaussian, stanvars = stanvars, data=HED, prior =  c(prior(normal(0, 3), class = "b", coef = ""), prior(normal(0, 100), class = "Intercept", coef = ""), prior(logistic(0, 0.5), class = "Intercept", dpar = "hu")), sample_prior = T, save_pars = save_pars(all = TRUE), chains = chains,  iter = niter, warmup = warm, seed = 123, inits = 1, backend = 'cmdstan', threads = threading(4), control = list(adapt_delta = 0.99))# a lot to unwind here.. 1)  custom gaussian hurdle cause zero-inflated continous data 2) Generic weakly informative prior around 0 for fixed effects and very weak prior for the intercept 3) we need to sample priors and save parameters for computing BF #this one is a big longer, so seat tight 4) increased step size

#lmer to compare
fmod_full = lmer(mf , data = HED, REML=F, control = control)

```


```{r message = FALSE, results='hide', fig.align="center", out.width = "100%", dpi = 200}

## plot population-level effects posterior distributions and chain sampling
param = mcmc_plot(object = bmod_full,  pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1", "b_int", "b_fam"), type ="areas")  # int and fam

trace = mcmc_plot(object = bmod_full,  pars =c("b_.*o", "b_.*y", "b_.*ge", "b_.*diff", "b_.*V1", "b_int", "b_fam"), type ="trace")


#check assumptions
var_group = pp_check(bmod_full, type = "stat_grouped", stat = "median", group = "intervention", binwidth = 0.1, nsamples = NULL) #equality of variance between groups

rep_fit = pp_check(bmod_full, nsamples = 10) # check response fit 

error = pp_check(bmod_full, type ="error_scatter_avg", nsamples = NULL) # check good alignment between model and data, and no obvious pattern to the types of errors we are getting.


#Normality of errors
residuals <-residuals(bmod_full)[, 1]; res <- qqnorm(residuals, pch = 1, plot.it=F)

lmx = plot_model(fmod_full, type = "diag"); #diagnostic plots for lmer

#plot all
diagPIT <- ggarrange(param, var_group, rep_fit, error, ncol = 2, nrow = 2)

annotate_figure(diagPIT, top = text_grob("Diagnostic Plots", face = "bold", size = 10))
# check response fit -> capture better the weird (bimodal at least..) distrib
# residual ... could be better but at least it's MUCH better than simple gaussian see lmx[1] ... this is just catastrophic..
```





```{r HED_res, cache=F, results='hide'}

full_tab = describe_posterior(bmod_full,
                   estimate = "median", dispersion = T,
                   ci = .9, ci_method = "hdi",
                   bf_prior = bmod_full, diagnostic = "Rhat",  
                   test = c("p_direction", "bf"))



full_tab = filter(full_tab, Parameter %notin% c("b_Intercept", "b_hu_Intercept", "prior_sigma"))


#contrasts 
# emmip(bmod_full, condition~intervention) to visualize
# 
# ems = emmeans(bmod_full, ~condition|intervention)
# con_inter = contrast(ems, interaction = "pairwise", by = NULL)
# 
# 
# inter_tab = describe_posterior(con_inter,
#                    estimate = "median", dispersion = TRUE,
#                    ci = .9, ci_method = "hdi",
#                    bf_prior = bmod_full, diagnostic = "Rhat",  
#                    test = c("p_direction", "bf"))



# -------------------------------------- FREQUENTIST STATS: LRT + Bootstrap  -----------------------------------------------

# fmod_cond = update(fmod_full,  ~ .-condition) #evaluate condition

# # p-value from bootstrap distribution
# LRT_cond = PBmodcomp(fmod_full, fmod_cond, nsim = 500, seed = 123, cl=cores) 

# -------------------------------------- Regression table summary --------------------------------------

tab_model(bmod_full, show.p = F,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Perceived liking", file = "tmp/temp6.html", transform = NULL,  rm.terms = "hu_Intercept")

report = capture.output(sexit(bmod_full, ci=.9))

```


```{r HED_tab}
print(paste("Bayesian general linear mixed model (hurdle gaussian family with a identity link) (estimated using MCMC sampling with", chains," chains of", niter, " iterations and a warmup of", warm, ") to predict Perceived Liking with condition, intervention, session, age, gender, BMI_V1, hungry, GLP_diff and reelin_diff (formula: perceived_liking ~ condition * intervention * session + age + gender + BMI_V1 + hungry + GLP_diff + reelin_diff + int + fam). The model included condition, session, id and trialxcondition as random effects (formula: list(~condition | id, ~1 | trialxcondition)). Priors over parameters were set as normal (mean = 0.00, SD = 3.00) and student_t (location = 0.00, scale = 31.7) distributions for beta and sd respectively"))
            

full_tab

report[5]


tables <- list.clean(readHTMLTable("tmp/temp6.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble(); 

tables2[is.na(tables2)] <- "";  names(tables2) <- NULL; tmp = t(tables2[(length(full_tab$Parameter)+1):(length(full_tab$Parameter)+5),1:2]);
tmp[,5][1] = "R2"; tmp[,5][2] = gsub(".*/","",tmp[,5][2])
pander::pander(tmp)
```

#### Plot {-}

```{r HED_plot, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="A) Posterior distribution by group. B) Highest density interval (90% HDI) for the interaction condition by session"}

# plot HDI
dfdraws = bmod_full %>%
    spread_draws(`b_condition` )

HDI_HED = plotHDI( dfdraws$`b_condition` , credMass = .90, binSize = 100, Title = "") + theme_bw()


#plot estimated means from posterior distribution from the model draws


dfdraws2 =  bmod_full %>%
     emmeans(~ condition) %>%
     gather_emmeans_draws() 


pp = dfdraws2 %>% #diff
    ggplot(aes(x = as.factor(condition) , y = .value,  fill = as.factor(condition))) +
    #geom_abline(slope= 0, intercept=0, linetype = "dashed", color = "black") +
    #geom_point(position = "jitter") +
    stat_slab(.width = c(0.50, 0.9), position="dodge", alpha=0.5) +
    stat_pointinterval(.width = c(0.50, 0.9),position="dodge") +
    labs(x = "", y = "Perceived liking", title = "") + 
    scale_fill_manual(values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
    scale_color_manual( values=c("-1" = pal[1],"1"=pal[3]), guide="none") +
    scale_x_discrete(labels=c("Tasteless", "Milkshake")) +
    scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
    theme_bw()


plt_bayes_html = pp + html_theme 
plt_bayes = pp + averaged_theme 


figureHED <- ggarrange(plt_bayes_html, HDI_HED,
                    labels = c("A", "B"),
                    ncol = 2)
#figureHED


# AVERAGED EFFECT
dfH <- summarySEwithin(HED.means,
                       measurevar = "perceived_liking",
                       withinvars = c("condition","session"),
                       idvar = "id")

dfH$cond <- ifelse(dfH$condition == "1", -0.25, 0.25)
HED.means$cond <- ifelse(HED.means$condition == "1", -0.25, 0.25)
HED.means <- HED.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
                                  grouping = interaction(id, cond))


pp <- ggplot(HED.means, aes(x = cond, y = perceived_liking,
                            fill = as.factor(condition), color = as.factor(condition))) +
  geom_point(data = dfH, alpha = 0.5) +
  geom_line(aes(x = condjit, group = id, y = perceived_liking), alpha = .3, size = 0.5, color = 'gray') +
  geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = as.factor(condition), color = NA))+
  geom_point(aes(x = condjit, shape = as.factor(intervention)), alpha = .3,) +
  geom_crossbar(data = dfH, aes(y = perceived_liking, ymin=perceived_liking-se, ymax=perceived_liking+se), width = 0.2 , alpha = 0.1)+
  ylab('Perceived liking') +
  xlab('Taste') +
  scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) +
  scale_x_continuous(labels=c("Pleasant", "Neutral"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
  scale_fill_manual(values=c("1"= pal[3], "-1"=pal[1]), guide = 'none') +
  scale_color_manual(values=c("1"=pal[3], "-1"=pal[1]), guide = 'none') +
  scale_shape_manual(name="Intervention", labels=c("Placebo", "Liraglutide"), values = c(1, 2)) +
  theme_bw()+ facet_wrap(~session, labeller=labeller(session = labels))


pp + html_theme +theme(legend.position=c(.96,.94))
plt = pp + averaged_theme +theme(legend.position=c(.96,.94))
```


```{r HED_time, warning=FALSE,  message = FALSE, results='hide', fig.align="center", fig.cap="Perceived liking for each condition and group over trials."}


# PLOT OVERTIME


pp <- ggplot(HED.p, aes(x = as.numeric(trial), y = perceived_liking,
                        color = condition,
                        fill  = condition))+
    geom_point(data = HED.group, aes(shape = intervention, color = condition), alpha = 0.3) +
  geom_line(alpha = .5, size = 1, show.legend = F) +
  geom_ribbon(aes(ymax = perceived_liking + se, ymin = perceived_liking - se),  alpha=0.4) +
  geom_point() +
  ylab('Perceived Liking')+
  xlab('Trial')+
  scale_color_manual(labels = c('Pleasant', 'Neutral'), name = "",
                     values = c( "1" =pal[3], '-1' =pal[1])) +
  scale_fill_manual(labels = c('Pleasant', 'Neutral'), name = "",
                    values = c( "1" =pal[3], '-1'=pal[1])) +
  scale_y_continuous(expand = c(0, 0),  limits = c(0,100),  breaks=c(seq.int(0,100, by = 20))) +
    #scale_x_continuous(expand = c(0, 0),  limits = c(0,21),  breaks=c(seq.int(1,21, by = 2))) +
  guides(color=guide_legend(override.aes=list(fill=c(pal[3], pal[1]), color=c(pal[3], pal[1]))))+
    scale_shape_manual(name="Group", labels=c("Placebo", "Liraglutide"), values = c(1, 2, 18)) +
  theme_bw() +
  facet_wrap(~session, labeller=labeller(session =labels))


pp + html_theme + theme(strip.background = element_rect(fill="white"), legend.justification = "top", legend.position="right", axis.text.x = element_text(size = 14))
plt = pp + averaged_theme + theme(strip.background = element_rect(fill="white"), axis.text.x = element_text(size = 14), legend.justification = "top", legend.position="right")



##We see here the base difference between Placebo VS Liraglutide BUT it's the same for both sessions so .. no effect of the treatment really XXXX

# bmod_time = update(bmod_full,  ~ .+as.factor(trialxcondition)) #evaluate interaction
# 
# df =  bmod_time %>%
#      emmeans(~ condition:session:trialxcondition) 
# 
# 
# 
# bayes_plt = as_tibble(df) %>%
#     ggplot(aes(x = trialxcondition, y = emmean,  fill =as.factor(condition))) +
#     #geom_point(position = "jitter") +
#     geom_smooth(method=loess, se = T,inherit.aes = T) + 
#     #stat_slab(.width = c(0.50, 0.95),position="dodge", alpha=0.5) +
#     #stat_pointinterval(.width = c(0.50, 0.95),position="dodge") +
#     ylab('Mobilized effort (a.u.) \n Baseline corrected')+
#     xlab('')+
#     scale_fill_manual(values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     scale_color_manual( values=c("1" = pal[2],"-1"=pal[1]), guide="none") +
#     #scale_x_discrete(labels=c("CS+", "CS-")) +
#     theme_bw() + facet_wrap(~session, labeller=labeller(session =labels))

```
\
\


```{r HED_save, results = "hide"}

cairo_pdf('figures/Figure_HED_Lira.pdf')
print(plt)
dev.off()

cairo_pdf('figures/Figure_HED_Lira_Bayes.pdf')
print(figureHED)
dev.off()
```

This part are not run here for different reasons (time it take and need to be on the cluster)
```{octave, eval=FALSE}
cwd=pwd
cd /home/OBIWAN/LIRA/fMRI/HED_GLM

```
# fMRI group Analysis

```{bash, eval = FALSE}
cwd=$(pwd)

cd /home/OBIWAN/DERIVATIVES/GLM/AFNI/hedonicreactivity/LIRA/ # go to fMRI directory


#I invite to take a look at the script
nohup bash -x HED.txt |& tee diary.txt & # runs the AFNI group analysis script in the background and output logs as it goes in the "diary.txt" file


#Convert from AFNI format to NIFTI #-prefix test lme+tlrc[i]
for i in  8 10 12
  do 3dAFNItoNIFTI -prefix LME_8_con${i}_z LME_8+tlrc[${i}]
     fslmaths LME_8_con${i}_z -ztop -add -1 -mul -1 LME_8_con${i}_1-p # convert to pvalue then inverse it for display 
done

cd $cwd

```

check out "analysis_LIRA_fMRI.R" for more details
```{r HED_fmri,  warning=FALSE}

# mdl.hf = aov_car(data = inter, HF_inter ~ intervention + BMI_diff + age + Error(id), factorize = F, type = "II", anova_table = list(correction = "GG", es = "pes"))
# 
# res = nice(mdl.hf, MSE=F); ref_grid(mdl.hf)  #triple check everything is centered at 0
# 
# 
# #calculate Partial eta-squared and its 90 % CI for each effect
# PES.hf = pes_ci(data = inter, HF_inter ~ intervention + BMI_diff + age + Error(id), conf.level = .90, factorize = FALSE, anova.type = "II", epsilon="none") ;
# mdl.hf.emms = emmeans(mdl.hf, pairwise ~ intervention)

```
Contrast Post > Pre in HF
\
```{r HED_fmri_res, message=F, warning=F}
# res$p.value = as.numeric(res$p.value)
# res$p.value = ifelse(res$p.value < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",res$p.value), "</span>"),  paste("<span>" ,sprintf("%.3f",res$p.value), "</span>"))
# 
# res$F = unlist(str_split(gsub("[^0-9.,-]", "", res$F), ","));res$pes = unlist(str_split(gsub("[^0-9.,-]", "", res$pes), ","));
# res$`90% CI` = paste(sprintf("%.3f",PES.hf[,2]), "-", sprintf("%.3f",PES.hf[,3]))
# 
# res$p.value[1]= "<span style=\" font-weight: bold;    \" >\u003C 0.001</span>"
# #res$pes[c(5,7,8)]= c("\u003C 0.001")
# colnames(res)[3:5] = c( paste("F(", res$df[1], ")", sep=""),"&eta;<sub>p</sub><sup>2</sup>", "p")
# res[c(1,4,6,3,5)]  %>% kbl(digits = 2, escape = F,row.names = F)  %>%
#   kable_styling(latex_options = "striped", position = "center", full_width = F)
# #print('PES: intervention: Overall higher weight loss for treament (Liraglutide) group')
# #PES.weight[1,]
```
```{r message = FALSE,  results='hide', fig.show="hold", out.width="25%", fig.align="center", fig.cap = 'Model assumptions.', warning=F}
# mod = lm(HF_inter ~ intervention + BMI_diff + age, data = inter)
# x = plot_model(mod, type = "diag")
# x[c(2,3,4,1)]
 #check assumptions
```
\
\
<!-- ```{r HED_fmri_plot,   message=FALSE, cache=TRUE, fig.align="right", fig.cap="Beta estimates from hippocampal formation during Hedonic reactivity test (Post > Pre) by intervention and correlation with weight loss.", warning=F} -->
<!-- sp = ggplot(inter, aes(x = `Weight Loss`, y = HF_inter, color = intervention)) + -->
<!--   stat_ellipse(aes(group=intervention)) +  geom_point(alpha = .3, size = 3) +  -->
<!--   geom_smooth(method= lm,aes(color = NULL), alpha = 0.5 ) + -->
<!--   scale_color_manual(name="Intervention", labels = c("Placebo", "Liraglutide"), values=c("0"=pal[1], "1"=pal[6])) + -->
<!--   theme_bw()+  -->
<!--   #stat_cor(aes(color=NULL, label = paste(..rr.label.., sep = "~`,`~")),label.x = 5, label.y = -2.5)+ labs(color = "Intervention")   +  # to add Rsquared  -->
<!--   guides(color = guide_legend(override.aes = list(fill=NA, size = c(2.5,2.5), linetype = c(0, 0),label = "") ) ) +   ylab('HF Beta estimates (a.u.)') +   xlab('Weight loss (\u0394 BMI)') +   theme(legend.title = element_text(size =12), legend.text = element_text(size = 10), axis.title.x = element_text(size = 24), axis.title.y = element_text(size =  24), legend.position = c(0.94, 0.9)) +  -->
<!--   border()    -->

<!-- xplot <- ggdensity(inter, "Weight Loss", fill = "intervention") +   scale_fill_manual(values=c("0"= pal[1], "1"=pal[6]))  -->
<!-- yplot <- ggdensity(inter, "HF_inter", fill = "intervention")  + scale_fill_manual(values=c("0"= pal[1], "1"=pal[6])) + rotate() -->

<!-- # Cleaning the plots -->
<!-- yplot <- yplot + clean_theme() + rremove("legend")  -->
<!-- xplot <- xplot + clean_theme() + rremove("legend") -->

<!-- fig = cowplot::plot_grid(xplot, NULL, sp, yplot,ncol = 2, align = "hv", rel_widths = c(2, 1), rel_heights = c(1, 2)) -->
<!-- fig -->
<!-- ``` -->
<!-- ```{r HED_fmri_saveFIG,  warning=FALSE} -->
<!-- cairo_pdf('figures/Figure_HED_fmri_Weight_HF.pdf') -->
<!-- print(fig) -->
<!-- dev.off() -->
<!-- ``` -->

<!-- ```{r hpp_mediation, cache=T,  warning=FALSE} -->
<!-- inter_res <- intmed::mediate(y = "`Weight Loss`", med = "HF", c = c("age"), treat = "Intervention", ymodel = "regression", mmodel = "regression", treat_lv = 1, control_lv = 0, conf.level = 0.95, data = inter, complete_analysis = T, digits = 3, summary_report=F) -->

<!-- tables <- list.clean(readHTMLTable("res.html"), fun = is.null, recursive = FALSE) -->

<!-- #just to plot -->
<!-- medi =  psych::mediate(`Weight Loss` ~ Intervention + (HF) -age, data = inter, plot=F) -->
<!-- ``` -->

<!-- \ -->
<!-- ```{r hpp_mediate_res} -->
<!-- table = tables[[3]] -->
<!-- table$Estimates = unlist(str_split(gsub("[^0-9.,-]", "", table$Estimates), ",")) -->

<!-- table$`p-value` = as.numeric(table$`p-value`); table$`p-value` = ifelse(as.numeric(table$`p-value`) < 0.05,paste("<span style=\" font-weight: bold; \" >" ,sprintf("%.3f",table$`p-value`), "</span>"),  paste("<span>" ,sprintf("%.3f",table$`p-value`), "</span>")) -->

<!-- table[2:3,4] = "<span style=\" font-weight: bold; \" > \u003C 0.001 <span>" -->
<!-- colnames(table)[4] = "p" -->
<!-- table$p[4] = "" -->
<!-- table %>% -->
<!--   kbl(caption ="Mediation Analysis: DV = Weight loss, IV = HF activity during reward consumption", escape =F) %>% -->
<!--   kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) -->
<!-- ``` -->
<!-- ```{r , fig.align="center", fig.cap="Mediation path.", fig.height = 2, fig.width = 7} -->
<!-- par(mar=c(0,0,0,0)); psych::mediate.diagram(medi, show.c = F, main= "", ylim=c(4.5,7.3)) -->
<!-- text(3, 6.5, "A ***",  cex = .8); text(7, 6.5, "B *",  cex = .8);  text(5.8, 4.9, "***",  cex = .8); text(5, 6.7, "AB *",  cex = .8) -->
<!-- ``` -->
<!-- \ -->
<!-- ```{r HED_fmri_plot_HF,   message=FALSE, cache=TRUE, fig.align="right", fig.cap="Beta estimates from hippocampal formation during Hedonic reactivity testby session by intervention.", warning=F} -->
<!-- # AVERAGED EFFECT ------------- -->
<!-- dfH <- summarySEwithin(HED_fMRI, -->
<!--                        measurevar = "HF_score", -->
<!--                        withinvars = "session", -->
<!--                        betweenvars = "intervention", -->
<!--                        idvar = "id") -->

<!-- labels <- c("0" = "Placebo", "1" = "Liraglutide") -->

<!-- HED_fMRI$intervention = as.factor(HED_fMRI$intervention) -->

<!-- dfH$cond <- ifelse(dfH$session == "pre", -0.25, 0.25) -->
<!-- HED_fMRI$cond <- ifelse(HED_fMRI$session == "pre", -0.25, 0.25) -->
<!-- HED_fMRI <- HED_fMRI %>% mutate(condjit = jitter(as.numeric(cond), 0.3), -->
<!--                                   grouping = interaction(id, cond)) -->


<!-- pp <- ggplot(HED_fMRI, aes(x = cond, y = HF_score,  fill = intervention, color = intervention)) + -->
<!--   geom_hline(yintercept = 0, lty=2) + -->
<!--   geom_point(data = dfH, alpha = 0.5) + -->
<!--   geom_line(aes(x = condjit, group=id), alpha = 0.2) + -->
<!--   geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(group = session, fill = intervention, color = NA))+ -->
<!--   geom_point(aes(x = condjit), alpha = .3) + -->
<!--   geom_crossbar(data = dfH, aes(y = HF_score, ymin=HF_score-se, ymax=HF_score+se), width = 0.2 , alpha = 0.1)+ -->
<!--   ylab('Beta estimates HF (a.u.)') + -->
<!--   xlab('') + -->
<!--   #scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) + -->
<!--   scale_x_continuous(labels=c("Pre", "Post"),breaks = c(-.25,.25), limits = c(-.5,.5)) + -->
<!--   scale_fill_manual(values=c("0"= pal[1], "1"=pal[6]), guide = 'none') + -->
<!--   scale_color_manual(values=c("0"=pal[1], "1"=pal[6]), guide = 'none') + -->
<!--   theme_bw()+ facet_wrap(~intervention, labeller=labeller(intervention = labels)) -->


<!-- ppp <- pp + averaged_theme -->
<!-- pp + html_theme -->
<!-- ``` -->
<!-- ```{r} -->
<!-- cairo_pdf('figures/Figure_HED_fmri_HF.pdf') -->
<!-- print(ppp) -->
<!-- dev.off() -->
<!-- ``` -->

<!-- ```{r HED_fmri_plot_OFC,   message=FALSE, cache=TRUE, fig.align="right", fig.cap="Beta estimates from OFC during Hedonic reactivity test by session by intervention."} -->
<!-- # AVERAGED EFFECT ------------- -->
<!-- dfH <- summarySEwithin(HED_fMRI, -->
<!--                        measurevar = "OFC_score", -->
<!--                        withinvars = "session", -->
<!--                        betweenvars = "intervention", -->
<!--                        idvar = "id") -->

<!-- labels <- c("0" = "Placebo", "1" = "Liraglutide") -->

<!-- HED_fMRI$intervention = as.factor(HED_fMRI$intervention) -->

<!-- dfH$cond <- ifelse(dfH$session == "pre", -0.25, 0.25) -->
<!-- HED_fMRI$cond <- ifelse(HED_fMRI$session == "pre", -0.25, 0.25) -->
<!-- HED_fMRI <- HED_fMRI %>% mutate(condjit = jitter(as.numeric(cond), 0.3), -->
<!--                                   grouping = interaction(id, cond)) -->


<!-- pp <- ggplot(HED_fMRI, aes(x = cond, y = OFC_score,  fill = intervention, color = intervention)) + -->
<!--   geom_hline(yintercept = 0, lty=2) + -->
<!--   geom_point(data = dfH, alpha = 0.5) + -->
<!--   geom_line(aes(x = condjit, group=id), alpha = 0.2) + -->
<!--   geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(group = session, fill = intervention, color = NA))+ -->
<!--   geom_point(aes(x = condjit), alpha = .3) + -->
<!--   geom_crossbar(data = dfH, aes(y = OFC_score, ymin=OFC_score-se, ymax=OFC_score+se), width = 0.2 , alpha = 0.1)+ -->
<!--   ylab('Beta estimates OFC (a.u.)') + -->
<!--   xlab('') + -->
<!--   #scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(0,100, by = 20)), limits = c(-0.5,100.5)) + -->
<!--   scale_x_continuous(labels=c("Pre", "Post"),breaks = c(-.25,.25), limits = c(-.5,.5)) + -->
<!--   scale_fill_manual(values=c("0"= pal[1], "1"=pal[6]), guide = 'none') + -->
<!--   scale_color_manual(values=c("0"=pal[1], "1"=pal[6]), guide = 'none') + -->
<!--   theme_bw()+ facet_wrap(~intervention, labeller=labeller(intervention = labels)) -->


<!-- ppp <- pp + averaged_theme -->
<!-- pp + html_theme -->
<!-- ``` -->
<!-- ```{r} -->
<!-- cairo_pdf('figures/Figure_HED_fmri_OFC.pdf') -->
<!-- print(ppp) -->
<!-- dev.off() -->
<!-- ``` -->


#### Packages {-}


Thanks to all the package's authors and developers!
```{r, warning=F}
report::report_packages()

# aaronpeikert/repro@devel #repro, crsh/papaja@devel,knitr, afex #aov_car/lmer, emmeans #emmeans, parallel #detectCores, tidyverse ##ggplot/dplyr/plyr/tidyr, car #densityPlot, lspline # lspline, JWileymisc #egtable, kableExtra #kable_styling, glmnet #cv.glmnet, ggthemes #theme_fivethirtyeight,  MBESS #pes_ci, sjPlot #tab_model/plot_model, Rmisc #SummarySEwithin, janitor #row_to_names, rlist #list.clean, sessioninfo #sessioninfo, stringr #str_list, XML #readHTMLtable, bayestestR #bayesfactor_models, cmdstanr #multithead, ggpubr::ggarrange	#	Arrange Multiple ggplots, tidybayes #spread draws]  
```


